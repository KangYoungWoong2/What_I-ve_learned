{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 텐서플로 기초 \"\"\"\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#예제는 모두 https://github.com/hunkim/DeeplearningZerotoAll/\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, Tensorflow!'\n"
     ]
    }
   ],
   "source": [
    "# 값 출력하는 방법 - Session()\n",
    "\n",
    "hello = tf.constant('Hello, Tensorflow!')\n",
    "sess = tf.Session() # 텐서플로우는 세션을 통해서 값, 명령등을 수행\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sess.run(node1, node2):  [3.0, 4.0]\n",
      "sess.run(node3):  7.0\n"
     ]
    }
   ],
   "source": [
    "#텐서플로우는 기본적으로 그래프 틀을 먼저 짜고 그다음에 값을 넣는다고 생각\n",
    "\n",
    "#일단 값을 먼저 정해놓은 경우\n",
    "node1 = tf.constant(3.0, tf.float32) # 형식을 같이 지정할 수 있다\n",
    "node2 = tf.constant(4.0) # 기본 형식은 tf.float32\n",
    "node3 = tf.add(node1, node2) #노드 더하기\n",
    "\n",
    "sess = tf.Session()\n",
    "print(\"sess.run(node1, node2): \", sess.run([node1, node2])) #여러개의 노드를 실행할 때 [ ] 로 묶기\n",
    "print(\"sess.run(node3): \", sess.run(node3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "[3. 7.]\n"
     ]
    }
   ],
   "source": [
    "#값의 형식을 정해놓고 나중에 값을 입력하는 경우\n",
    "a = tf.placeholder(tf.float32) #값의 형식만 미리 정해놓기 -> 나중에 feed_dict를 이용해서 값을 입력하게 되\n",
    "b = tf.placeholder(tf.float32)\n",
    "adder_node = a + b  # 노드 더하기는 +로 표현가\n",
    "\n",
    "print(sess.run(adder_node, feed_dict={a: 3, b: 4.5}))\n",
    "print(sess.run(adder_node, feed_dict={a: [1,3], b: [2, 4]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.5\n"
     ]
    }
   ],
   "source": [
    "#노드 변경도 쉽게 가능\n",
    "add_and_triple = adder_node * 3.\n",
    "print(sess.run(add_and_triple, feed_dict={a: 3, b:4.5}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 19.712336 [-0.22502387] [-1.3703469]\n",
      "20 0.2416284 [1.1462271] [-0.7280558]\n",
      "40 0.0593196 [1.2644428] [-0.63881344]\n",
      "60 0.05242319 [1.2639256] [-0.60355204]\n",
      "80 0.04759842 [1.2526562] [-0.57468855]\n",
      "100 0.043229494 [1.2408903] [-0.5476327]\n",
      "120 0.039261732 [1.2295796] [-0.52189153]\n",
      "140 0.035658166 [1.2187911] [-0.49736413]\n",
      "160 0.032385293 [1.208509] [-0.4739898]\n",
      "180 0.02941285 [1.1987097] [-0.451714]\n",
      "200 0.026713246 [1.1893712] [-0.4304851]\n",
      "220 0.02426138 [1.1804714] [-0.41025394]\n",
      "240 0.022034576 [1.1719899] [-0.39097354]\n",
      "260 0.020012168 [1.1639073] [-0.37259924]\n",
      "280 0.018175365 [1.156204] [-0.35508847]\n",
      "300 0.01650715 [1.1488631] [-0.3384006]\n",
      "320 0.014992059 [1.1418669] [-0.32249704]\n",
      "340 0.013616023 [1.1351997] [-0.30734077]\n",
      "360 0.012366294 [1.1288458] [-0.29289693]\n",
      "380 0.011231276 [1.1227907] [-0.27913183]\n",
      "400 0.01020042 [1.1170199] [-0.26601374]\n",
      "420 0.009264182 [1.1115203] [-0.25351205]\n",
      "440 0.008413866 [1.1062793] [-0.24159786]\n",
      "460 0.0076416284 [1.1012847] [-0.23024371]\n",
      "480 0.0069402386 [1.0965245] [-0.21942304]\n",
      "500 0.0063032336 [1.0919883] [-0.20911098]\n",
      "520 0.005724695 [1.0876651] [-0.1992835]\n",
      "540 0.0051992685 [1.0835452] [-0.18991789]\n",
      "560 0.004722037 [1.0796187] [-0.18099232]\n",
      "580 0.004288648 [1.0758771] [-0.17248632]\n",
      "600 0.0038949999 [1.072311] [-0.1643801]\n",
      "620 0.0035375059 [1.0689127] [-0.1566548]\n",
      "640 0.0032128182 [1.0656741] [-0.14929262]\n",
      "660 0.0029179351 [1.0625879] [-0.14227642]\n",
      "680 0.0026501177 [1.0596462] [-0.13559014]\n",
      "700 0.0024068784 [1.056843] [-0.12921782]\n",
      "720 0.0021859715 [1.0541717] [-0.12314506]\n",
      "740 0.0019853308 [1.0516257] [-0.11735767]\n",
      "760 0.0018031048 [1.0491996] [-0.11184223]\n",
      "780 0.0016376093 [1.0468873] [-0.10658601]\n",
      "800 0.001487302 [1.0446839] [-0.10157686]\n",
      "820 0.0013508009 [1.042584] [-0.09680319]\n",
      "840 0.0012268183 [1.0405828] [-0.09225389]\n",
      "860 0.0011142099 [1.0386753] [-0.08791827]\n",
      "880 0.0010119426 [1.0368577] [-0.08378641]\n",
      "900 0.0009190671 [1.0351256] [-0.07984874]\n",
      "920 0.00083471154 [1.0334748] [-0.07609614]\n",
      "940 0.0007580963 [1.0319016] [-0.0725199]\n",
      "960 0.0006885145 [1.0304023] [-0.06911171]\n",
      "980 0.0006253208 [1.0289735] [-0.06586368]\n",
      "1000 0.00056792604 [1.027612] [-0.06276834]\n",
      "1020 0.0005158009 [1.0263143] [-0.05981846]\n",
      "1040 0.00046845735 [1.0250776] [-0.05700721]\n",
      "1060 0.00042545842 [1.0238991] [-0.0543281]\n",
      "1080 0.00038641007 [1.0227759] [-0.05177493]\n",
      "1100 0.00035094444 [1.0217056] [-0.04934177]\n",
      "1120 0.00031873756 [1.0206859] [-0.04702303]\n",
      "1140 0.0002894839 [1.0197135] [-0.04481335]\n",
      "1160 0.0002629099 [1.0187868] [-0.04270718]\n",
      "1180 0.00023877894 [1.0179039] [-0.04070003]\n",
      "1200 0.00021686305 [1.0170625] [-0.03878726]\n",
      "1220 0.00019696083 [1.0162607] [-0.03696439]\n",
      "1240 0.00017888036 [1.0154965] [-0.03522722]\n",
      "1260 0.00016246227 [1.0147682] [-0.03357163]\n",
      "1280 0.00014755163 [1.0140742] [-0.03199389]\n",
      "1300 0.0001340095 [1.0134128] [-0.03049036]\n",
      "1320 0.0001217091 [1.0127823] [-0.02905739]\n",
      "1340 0.00011053794 [1.0121818] [-0.02769181]\n",
      "1360 0.00010039165 [1.0116091] [-0.02639038]\n",
      "1380 9.117883e-05 [1.0110636] [-0.02515013]\n",
      "1400 8.281001e-05 [1.0105437] [-0.02396821]\n",
      "1420 7.520841e-05 [1.010048] [-0.02284175]\n",
      "1440 6.830606e-05 [1.0095758] [-0.02176819]\n",
      "1460 6.2036146e-05 [1.0091258] [-0.02074514]\n",
      "1480 5.6341403e-05 [1.0086969] [-0.01977018]\n",
      "1500 5.1170995e-05 [1.0082881] [-0.01884104]\n",
      "1520 4.647288e-05 [1.0078987] [-0.01795558]\n",
      "1540 4.2208543e-05 [1.0075275] [-0.01711173]\n",
      "1560 3.8333415e-05 [1.0071738] [-0.01630755]\n",
      "1580 3.481578e-05 [1.0068365] [-0.01554116]\n",
      "1600 3.1620784e-05 [1.0065151] [-0.01481073]\n",
      "1620 2.8717253e-05 [1.0062091] [-0.01411466]\n",
      "1640 2.6082163e-05 [1.0059173] [-0.01345137]\n",
      "1660 2.368814e-05 [1.0056392] [-0.01281922]\n",
      "1680 2.1514004e-05 [1.0053742] [-0.01221677]\n",
      "1700 1.9539546e-05 [1.0051216] [-0.01164264]\n",
      "1720 1.7745735e-05 [1.0048808] [-0.01109543]\n",
      "1740 1.6117256e-05 [1.0046515] [-0.01057396]\n",
      "1760 1.4637852e-05 [1.0044329] [-0.01007705]\n",
      "1780 1.329439e-05 [1.0042247] [-0.0096035]\n",
      "1800 1.2073924e-05 [1.004026] [-0.00915219]\n",
      "1820 1.0965864e-05 [1.0038368] [-0.00872207]\n",
      "1840 9.9595345e-06 [1.0036566] [-0.00831217]\n",
      "1860 9.04565e-06 [1.0034847] [-0.00792154]\n",
      "1880 8.215451e-06 [1.003321] [-0.0075493]\n",
      "1900 7.4613613e-06 [1.0031649] [-0.00719451]\n",
      "1920 6.776514e-06 [1.0030162] [-0.00685643]\n",
      "1940 6.154262e-06 [1.0028745] [-0.00653424]\n",
      "1960 5.5894184e-06 [1.0027394] [-0.00622717]\n",
      "1980 5.0771796e-06 [1.0026107] [-0.00593458]\n",
      "2000 4.6110667e-06 [1.002488] [-0.00565573]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Linear Regression \"\"\"\n",
    "x_train = [1, 2, 3]\n",
    "y_train = [1, 2, 3]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name=\"weight\") # Variable은 trainable한 값이라고 생각(tf.constant와는 달리 최적화 과정을 통해 변하는 값)\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\") #tf.random_normal([1])을 통해 1개의 값을 임의로 배정\n",
    "\n",
    "hypothesis = x_train * W + b # 선형회귀식의 가설\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train)) #비용함수, MSE를 적용\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01) #옵티마이저 설정 - 경사하강법\n",
    "train = optimizer.minimize(cost) #cost를 minimizing하는 과정을 train 노드에 배치\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer()) #W와 b에 tf.Variable을 사용했으므로 세션 시작 시 이에 대한 초기화를 해줘야함\n",
    "\n",
    "    for step in range(2001): #2000번 학습\n",
    "        _, cost_val, W_val, b_val = sess.run([train, cost, W, b]) # train을 run하는 것으로 그래프 상의 모든 값들을 활용한다고 볼 수 있음\n",
    "\n",
    "        if step % 20 == 0:\n",
    "            print(step, cost_val, W_val, b_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 28.305643 [-0.73439175] [-1.044567]\n",
      "20 0.2638547 [0.92388463] [-0.30185398]\n",
      "40 0.008945569 [1.0776002] [-0.22162177]\n",
      "60 0.0060328804 [1.0882496] [-0.2049175]\n",
      "80 0.005460189 [1.0854634] [-0.19468829]\n",
      "100 0.004958873 [1.0815766] [-0.18548165]\n",
      "120 0.004503716 [1.0777551] [-0.17675926]\n",
      "140 0.004090353 [1.074102] [-0.16845174]\n",
      "160 0.003714925 [1.0706197] [-0.16053513]\n",
      "180 0.0033739563 [1.0673008] [-0.15299058]\n",
      "200 0.0030642748 [1.0641379] [-0.14580059]\n",
      "220 0.0027830238 [1.0611236] [-0.1389485]\n",
      "240 0.0025275853 [1.058251] [-0.1324183]\n",
      "260 0.0022955944 [1.0555134] [-0.12619512]\n",
      "280 0.002084901 [1.0529046] [-0.12026444]\n",
      "300 0.0018935386 [1.0504181] [-0.11461245]\n",
      "320 0.0017197421 [1.0480487] [-0.10922606]\n",
      "340 0.0015618963 [1.0457906] [-0.10409282]\n",
      "360 0.001418537 [1.0436387] [-0.09920083]\n",
      "380 0.0012883387 [1.0415877] [-0.09453881]\n",
      "400 0.0011700843 [1.0396329] [-0.09009567]\n",
      "420 0.0010626873 [1.0377706] [-0.08586141]\n",
      "440 0.000965152 [1.0359955] [-0.08182624]\n",
      "460 0.0008765636 [1.0343039] [-0.0779807]\n",
      "480 0.0007961068 [1.0326917] [-0.0743159]\n",
      "500 0.0007230433 [1.0311553] [-0.07082333]\n",
      "520 0.0006566776 [1.0296911] [-0.06749493]\n",
      "540 0.00059640524 [1.0282958] [-0.0643229]\n",
      "560 0.0005416679 [1.0269661] [-0.06129999]\n",
      "580 0.000491947 [1.0256987] [-0.05841913]\n",
      "600 0.00044679464 [1.024491] [-0.05567361]\n",
      "620 0.00040578863 [1.02334] [-0.0530572]\n",
      "640 0.00036854218 [1.022243] [-0.05056372]\n",
      "660 0.00033471745 [1.0211978] [-0.04818749]\n",
      "680 0.00030399926 [1.0202017] [-0.04592298]\n",
      "700 0.000276093 [1.019252] [-0.04376469]\n",
      "720 0.0002507514 [1.0183473] [-0.04170784]\n",
      "740 0.00022773772 [1.0174851] [-0.0397477]\n",
      "760 0.000206833 [1.0166633] [-0.03787969]\n",
      "780 0.0001878502 [1.0158802] [-0.0360995]\n",
      "800 0.00017060828 [1.0151339] [-0.03440293]\n",
      "820 0.00015495 [1.0144227] [-0.03278611]\n",
      "840 0.00014072742 [1.0137448] [-0.03124528]\n",
      "860 0.00012781048 [1.0130988] [-0.02977684]\n",
      "880 0.00011607923 [1.0124834] [-0.02837747]\n",
      "900 0.00010542572 [1.0118966] [-0.02704381]\n",
      "920 9.57481e-05 [1.0113375] [-0.02577285]\n",
      "940 8.696012e-05 [1.0108048] [-0.0245616]\n",
      "960 7.898044e-05 [1.010297] [-0.02340736]\n",
      "980 7.172911e-05 [1.009813] [-0.02230724]\n",
      "1000 6.5146414e-05 [1.0093518] [-0.02125886]\n",
      "1020 5.916755e-05 [1.0089123] [-0.02025978]\n",
      "1040 5.3736698e-05 [1.0084934] [-0.01930765]\n",
      "1060 4.880469e-05 [1.0080943] [-0.01840028]\n",
      "1080 4.4324843e-05 [1.0077139] [-0.01753553]\n",
      "1100 4.0256873e-05 [1.0073514] [-0.01671143]\n",
      "1120 3.6561763e-05 [1.0070059] [-0.01592609]\n",
      "1140 3.3205593e-05 [1.0066766] [-0.01517759]\n",
      "1160 3.0157762e-05 [1.0063628] [-0.01446426]\n",
      "1180 2.7389857e-05 [1.0060638] [-0.01378449]\n",
      "1200 2.4876317e-05 [1.0057788] [-0.01313667]\n",
      "1220 2.2592822e-05 [1.0055072] [-0.01251925]\n",
      "1240 2.0519403e-05 [1.0052484] [-0.01193088]\n",
      "1260 1.8635217e-05 [1.0050017] [-0.01137013]\n",
      "1280 1.6924998e-05 [1.0047667] [-0.01083574]\n",
      "1300 1.5371417e-05 [1.0045427] [-0.01032651]\n",
      "1320 1.39601725e-05 [1.0043292] [-0.00984121]\n",
      "1340 1.2679874e-05 [1.0041258] [-0.00937878]\n",
      "1360 1.1515847e-05 [1.0039319] [-0.00893808]\n",
      "1380 1.0459332e-05 [1.0037471] [-0.00851802]\n",
      "1400 9.499166e-06 [1.003571] [-0.00811773]\n",
      "1420 8.6275895e-06 [1.0034033] [-0.00773628]\n",
      "1440 7.835491e-06 [1.0032432] [-0.00737273]\n",
      "1460 7.116363e-06 [1.0030909] [-0.00702624]\n",
      "1480 6.4633823e-06 [1.0029455] [-0.00669606]\n",
      "1500 5.8701094e-06 [1.0028073] [-0.00638141]\n",
      "1520 5.331811e-06 [1.0026754] [-0.00608157]\n",
      "1540 4.842011e-06 [1.0025495] [-0.0057958]\n",
      "1560 4.3977075e-06 [1.0024298] [-0.00552343]\n",
      "1580 3.9942975e-06 [1.0023156] [-0.00526387]\n",
      "1600 3.6275994e-06 [1.0022068] [-0.00501654]\n",
      "1620 3.2947728e-06 [1.0021031] [-0.00478079]\n",
      "1640 2.9923565e-06 [1.0020043] [-0.00455619]\n",
      "1660 2.717775e-06 [1.0019101] [-0.00434213]\n",
      "1680 2.4685878e-06 [1.0018204] [-0.00413814]\n",
      "1700 2.242074e-06 [1.001735] [-0.0039437]\n",
      "1720 2.036136e-06 [1.0016534] [-0.00375842]\n",
      "1740 1.8493268e-06 [1.0015758] [-0.00358189]\n",
      "1760 1.6798267e-06 [1.0015018] [-0.00341363]\n",
      "1780 1.5258028e-06 [1.0014313] [-0.00325332]\n",
      "1800 1.3857662e-06 [1.0013639] [-0.00310052]\n",
      "1820 1.2584774e-06 [1.0013] [-0.00295488]\n",
      "1840 1.1431896e-06 [1.001239] [-0.00281609]\n",
      "1860 1.0384194e-06 [1.0011808] [-0.00268383]\n",
      "1880 9.430228e-07 [1.0011252] [-0.00255776]\n",
      "1900 8.5659707e-07 [1.0010724] [-0.00243766]\n",
      "1920 7.779325e-07 [1.001022] [-0.00232318]\n",
      "1940 7.066212e-07 [1.000974] [-0.00221409]\n",
      "1960 6.418467e-07 [1.0009284] [-0.00211015]\n",
      "1980 5.8316203e-07 [1.0008849] [-0.00201108]\n",
      "2000 5.296514e-07 [1.0008434] [-0.00191667]\n",
      "[5.0023003]\n",
      "[2.500192]\n",
      "[1.4993484 3.5010352]\n"
     ]
    }
   ],
   "source": [
    "# placeholder를 사용하는 경우\n",
    "X = tf.placeholder(tf.float32, shape=[None]) \n",
    "Y = tf.placeholder(tf.float32, shape=[None])\n",
    "\n",
    "hypothesis = X * W + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(2001):\n",
    "        _, cost_val, W_val, b_val = sess.run(\n",
    "            [train, cost, W, b], feed_dict={X: [1, 2, 3], Y: [1, 2, 3]}\n",
    "        ) #feed_dict를 통해 값 넣어주기\n",
    "        if step % 20 == 0:\n",
    "            print(step, cost_val, W_val, b_val)\n",
    "\n",
    "    #예측값\n",
    "    print(sess.run(hypothesis, feed_dict={X: [5]}))\n",
    "    print(sess.run(hypothesis, feed_dict={X: [2.5]}))\n",
    "    print(sess.run(hypothesis, feed_dict={X: [1.5, 3.5]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#경사하강법을 직접 구현해보면?\n",
    "\n",
    "#직접 구현해 보기전 cost function의 형태를 먼저 확인해 보면\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = [1, 2, 3]\n",
    "Y = [1, 2, 3]\n",
    "\n",
    "W = tf.placeholder(tf.float32)\n",
    "\n",
    "hypothesis = X * W #hypothesis를 단순화\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "W_history = []\n",
    "cost_history = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for i in range(-30, 50):\n",
    "        curr_W = i * 0.1 #W는 -3부터 5까지 움직이게 됨\n",
    "        curr_cost = sess.run(cost, feed_dict={W: curr_W})\n",
    "\n",
    "        W_history.append(curr_W)\n",
    "        cost_history.append(curr_cost)\n",
    "\n",
    "# 그래프 그리기\n",
    "plt.plot(W_history, cost_history)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.1774526 [0.49539557]\n",
      "1 1.1882529 [0.73087764]\n",
      "2 0.33799195 [0.8564681]\n",
      "3 0.09613996 [0.92344964]\n",
      "4 0.027346455 [0.95917314]\n",
      "5 0.007778555 [0.9782257]\n",
      "6 0.0022125589 [0.98838705]\n",
      "7 0.00062935107 [0.9938064]\n",
      "8 0.00017901452 [0.99669677]\n",
      "9 5.091913e-05 [0.99823827]\n",
      "10 1.4484183e-05 [0.9990604]\n",
      "11 4.120025e-06 [0.9994989]\n",
      "12 1.1717283e-06 [0.99973273]\n",
      "13 3.3334825e-07 [0.9998575]\n",
      "14 9.476506e-08 [0.999924]\n",
      "15 2.6942715e-08 [0.99995947]\n",
      "16 7.666283e-09 [0.99997836]\n",
      "17 2.1820636e-09 [0.99998844]\n",
      "18 6.267413e-10 [0.99999386]\n",
      "19 1.7515944e-10 [0.9999967]\n",
      "20 4.976286e-11 [0.9999983]\n"
     ]
    }
   ],
   "source": [
    "#경사하강법 직접 구현\n",
    "x_data = [1, 2, 3]\n",
    "y_data = [1, 2, 3]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name=\"weight\") # 임의의 값을 직접 넣고 싶으면 W = tf.Variable(5.0) 이런식으로 넣으면 됨\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "hypothesis = X * W\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "learning_rate = 0.1\n",
    "gradient = tf.reduce_mean((W * X - Y) * X) #gradient는 cost function을 미분한 값 ∂(1/2m)∑(WX - Y)^2 / ∂W = (1/m)∑(WX - Y)X\n",
    "descent = W - learning_rate * gradient # gradient에 학습률을 곱한 한 값을 W에서 뺴주기\n",
    "update = W.assign(descent) # W := W - a∂C/∂W 의 과정 ; 이 과정을 update란 노드에 배치\n",
    "# 위의 과정을 단순화 한 것이 train = tf.train.GradientOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(21):\n",
    "        _, cost_val, W_val = sess.run(\n",
    "            [update, cost, W], feed_dict={X: x_data, Y: y_data}\n",
    "        ) #update란 노드를 실행하는 것이 optimizer를 실행하는 것과 같음\n",
    "        print(step, cost_val, W_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [-11.815764, array([-0.2659747], dtype=float32), [(array([-11.815763], dtype=float32), array([-0.2659747], dtype=float32))]]\n",
      "1 [-0.7877178, array([0.9156017], dtype=float32), [(array([-0.7877179], dtype=float32), array([0.9156017], dtype=float32))]]\n",
      "2 [-0.052514315, array([0.99437344], dtype=float32), [(array([-0.05251431], dtype=float32), array([0.99437344], dtype=float32))]]\n",
      "3 [-0.0035011768, array([0.99962485], dtype=float32), [(array([-0.00350118], dtype=float32), array([0.99962485], dtype=float32))]]\n",
      "4 [-0.00023365021, array([0.99997497], dtype=float32), [(array([-0.00023365], dtype=float32), array([0.99997497], dtype=float32))]]\n",
      "5 [-1.5576681e-05, array([0.99999833], dtype=float32), [(array([-1.5576681e-05], dtype=float32), array([0.99999833], dtype=float32))]]\n",
      "6 [-1.3510386e-06, array([0.9999999], dtype=float32), [(array([-1.3510387e-06], dtype=float32), array([0.9999999], dtype=float32))]]\n",
      "7 [0.0, array([1.], dtype=float32), [(array([0.], dtype=float32), array([1.], dtype=float32))]]\n",
      "8 [0.0, array([1.], dtype=float32), [(array([0.], dtype=float32), array([1.], dtype=float32))]]\n",
      "9 [0.0, array([1.], dtype=float32), [(array([0.], dtype=float32), array([1.], dtype=float32))]]\n",
      "10 [0.0, array([1.], dtype=float32), [(array([0.], dtype=float32), array([1.], dtype=float32))]]\n",
      "11 [0.0, array([1.], dtype=float32), [(array([0.], dtype=float32), array([1.], dtype=float32))]]\n",
      "12 [0.0, array([1.], dtype=float32), [(array([0.], dtype=float32), array([1.], dtype=float32))]]\n",
      "13 [0.0, array([1.], dtype=float32), [(array([0.], dtype=float32), array([1.], dtype=float32))]]\n",
      "14 [0.0, array([1.], dtype=float32), [(array([0.], dtype=float32), array([1.], dtype=float32))]]\n",
      "15 [0.0, array([1.], dtype=float32), [(array([0.], dtype=float32), array([1.], dtype=float32))]]\n",
      "16 [0.0, array([1.], dtype=float32), [(array([0.], dtype=float32), array([1.], dtype=float32))]]\n",
      "17 [0.0, array([1.], dtype=float32), [(array([0.], dtype=float32), array([1.], dtype=float32))]]\n",
      "18 [0.0, array([1.], dtype=float32), [(array([0.], dtype=float32), array([1.], dtype=float32))]]\n",
      "19 [0.0, array([1.], dtype=float32), [(array([0.], dtype=float32), array([1.], dtype=float32))]]\n",
      "20 [0.0, array([1.], dtype=float32), [(array([0.], dtype=float32), array([1.], dtype=float32))]]\n"
     ]
    }
   ],
   "source": [
    "# Optimizer 활용시 gradient에 대한 조작을 하고 싶으면\n",
    "X = [1, 2, 3]\n",
    "Y = [1, 2, 3]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name=\"weight\") # 임의의 값을 직접 넣고 싶으면 W = tf.Variable(5.0) 이런식으로 넣으면 됨\n",
    "\n",
    "hypothesis = X * W\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "\n",
    "gvs = optimizer.compute_gradients(cost,[W])\n",
    "apply_gradients = optimizer.apply_gradients(gvs)\n",
    "\n",
    "gradient = tf.reduce_mean((W*X - Y)*X)*2\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(21):\n",
    "        print(step, sess.run([gradient,W, gvs])) # 직접 계산한 gradient와 optimizer를 사용했을 때의 gradient가 같은지 확인\n",
    "        sess.run(apply_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  6649.789 \n",
      "Prediction:\n",
      " [228.7069  267.66684 266.99042 293.75977 200.36853]\n",
      "10 Cost:  24.387854 \n",
      "Prediction:\n",
      " [156.68517 181.13481 181.71198 200.89467 134.37372]\n",
      "20 Cost:  24.213917 \n",
      "Prediction:\n",
      " [156.45006 180.88487 181.4488  200.60905 134.1904 ]\n",
      "30 Cost:  24.101234 \n",
      "Prediction:\n",
      " [156.43219 180.89597 181.44286 200.60356 134.20615]\n",
      "40 Cost:  23.989304 \n",
      "Prediction:\n",
      " [156.41504 180.90778 181.43771 200.59894 134.22244]\n",
      "50 Cost:  23.87786 \n",
      "Prediction:\n",
      " [156.39795 180.91962 181.43259 200.59433 134.23871]\n",
      "60 Cost:  23.76698 \n",
      "Prediction:\n",
      " [156.38089 180.9314  181.42749 200.58972 134.25494]\n",
      "70 Cost:  23.65675 \n",
      "Prediction:\n",
      " [156.36389 180.94315 181.4224  200.58514 134.27113]\n",
      "80 Cost:  23.547058 \n",
      "Prediction:\n",
      " [156.34692 180.95488 181.41731 200.58055 134.28726]\n",
      "90 Cost:  23.437986 \n",
      "Prediction:\n",
      " [156.33    180.96654 181.41223 200.57597 134.30336]\n",
      "100 Cost:  23.3295 \n",
      "Prediction:\n",
      " [156.31316 180.97823 181.40721 200.57144 134.31943]\n",
      "110 Cost:  23.221567 \n",
      "Prediction:\n",
      " [156.29633 180.98984 181.40216 200.56688 134.33543]\n",
      "120 Cost:  23.114222 \n",
      "Prediction:\n",
      " [156.27954 181.0014  181.39713 200.56232 134.3514 ]\n",
      "130 Cost:  23.007412 \n",
      "Prediction:\n",
      " [156.26282 181.01297 181.39212 200.5578  134.36734]\n",
      "140 Cost:  22.90124 \n",
      "Prediction:\n",
      " [156.24614 181.0245  181.38713 200.5533  134.38322]\n",
      "150 Cost:  22.795574 \n",
      "Prediction:\n",
      " [156.2295  181.03601 181.38216 200.5488  134.39908]\n",
      "160 Cost:  22.690567 \n",
      "Prediction:\n",
      " [156.21292 181.04744 181.37717 200.5443  134.41487]\n",
      "170 Cost:  22.58602 \n",
      "Prediction:\n",
      " [156.19637 181.05888 181.37224 200.53981 134.43063]\n",
      "180 Cost:  22.482067 \n",
      "Prediction:\n",
      " [156.17989 181.0703  181.3673  200.53535 134.44637]\n",
      "190 Cost:  22.378681 \n",
      "Prediction:\n",
      " [156.16344 181.08167 181.36237 200.53088 134.46204]\n",
      "200 Cost:  22.275747 \n",
      "Prediction:\n",
      " [156.14702 181.093   181.35745 200.52643 134.47769]\n",
      "210 Cost:  22.173546 \n",
      "Prediction:\n",
      " [156.13069 181.10431 181.35257 200.522   134.49329]\n",
      "220 Cost:  22.071743 \n",
      "Prediction:\n",
      " [156.11436 181.11559 181.34769 200.51755 134.50883]\n",
      "230 Cost:  21.970499 \n",
      "Prediction:\n",
      " [156.0981  181.12683 181.34282 200.51314 134.52437]\n",
      "240 Cost:  21.869837 \n",
      "Prediction:\n",
      " [156.08185 181.13803 181.33795 200.5087  134.53981]\n",
      "250 Cost:  21.769648 \n",
      "Prediction:\n",
      " [156.06567 181.14922 181.33311 200.5043  134.55527]\n",
      "260 Cost:  21.67006 \n",
      "Prediction:\n",
      " [156.04956 181.16039 181.3283  200.49992 134.57066]\n",
      "270 Cost:  21.57099 \n",
      "Prediction:\n",
      " [156.03348 181.1715  181.32347 200.49553 134.58601]\n",
      "280 Cost:  21.472427 \n",
      "Prediction:\n",
      " [156.01743 181.18259 181.3187  200.49117 134.60133]\n",
      "290 Cost:  21.37442 \n",
      "Prediction:\n",
      " [156.0014  181.19363 181.31387 200.48679 134.61658]\n",
      "300 Cost:  21.276907 \n",
      "Prediction:\n",
      " [155.98546 181.20468 181.30911 200.48245 134.63182]\n",
      "310 Cost:  21.17989 \n",
      "Prediction:\n",
      " [155.96954 181.21567 181.30435 200.47812 134.64703]\n",
      "320 Cost:  21.083427 \n",
      "Prediction:\n",
      " [155.95367 181.22664 181.2996  200.47377 134.66217]\n",
      "330 Cost:  20.987436 \n",
      "Prediction:\n",
      " [155.93785 181.23756 181.29486 200.46944 134.67729]\n",
      "340 Cost:  20.892033 \n",
      "Prediction:\n",
      " [155.92207 181.2485  181.29016 200.46515 134.69235]\n",
      "350 Cost:  20.797009 \n",
      "Prediction:\n",
      " [155.90633 181.25937 181.28546 200.46082 134.7074 ]\n",
      "360 Cost:  20.702555 \n",
      "Prediction:\n",
      " [155.89066 181.27023 181.28076 200.45654 134.72241]\n",
      "370 Cost:  20.608639 \n",
      "Prediction:\n",
      " [155.87498 181.28102 181.27608 200.45224 134.73735]\n",
      "380 Cost:  20.515205 \n",
      "Prediction:\n",
      " [155.85939 181.29182 181.27141 200.44798 134.75227]\n",
      "390 Cost:  20.422297 \n",
      "Prediction:\n",
      " [155.84381 181.30258 181.26675 200.44373 134.76714]\n",
      "400 Cost:  20.329817 \n",
      "Prediction:\n",
      " [155.8283  181.3133  181.26212 200.43945 134.78198]\n",
      "410 Cost:  20.23785 \n",
      "Prediction:\n",
      " [155.81284 181.32402 181.25749 200.43521 134.79678]\n",
      "420 Cost:  20.146408 \n",
      "Prediction:\n",
      " [155.7974  181.33469 181.25288 200.43098 134.81154]\n",
      "430 Cost:  20.055435 \n",
      "Prediction:\n",
      " [155.78201 181.34532 181.24828 200.42676 134.82626]\n",
      "440 Cost:  19.964928 \n",
      "Prediction:\n",
      " [155.76663 181.35593 181.24368 200.42253 134.84093]\n",
      "450 Cost:  19.874893 \n",
      "Prediction:\n",
      " [155.75134 181.36652 181.23912 200.41833 134.85559]\n",
      "460 Cost:  19.78536 \n",
      "Prediction:\n",
      " [155.73607 181.37706 181.23456 200.41414 134.8702 ]\n",
      "470 Cost:  19.696249 \n",
      "Prediction:\n",
      " [155.72086 181.38762 181.23    200.40996 134.88477]\n",
      "480 Cost:  19.607666 \n",
      "Prediction:\n",
      " [155.70569 181.39812 181.22548 200.40579 134.8993 ]\n",
      "490 Cost:  19.51956 \n",
      "Prediction:\n",
      " [155.69054 181.40855 181.22093 200.40161 134.91379]\n",
      "500 Cost:  19.43192 \n",
      "Prediction:\n",
      " [155.67545 181.419   181.21643 200.39746 134.92824]\n",
      "510 Cost:  19.344786 \n",
      "Prediction:\n",
      " [155.66039 181.42941 181.21194 200.39333 134.94264]\n",
      "520 Cost:  19.258005 \n",
      "Prediction:\n",
      " [155.64539 181.4398  181.20744 200.38918 134.95703]\n",
      "530 Cost:  19.171711 \n",
      "Prediction:\n",
      " [155.63043 181.45018 181.203   200.38506 134.97139]\n",
      "540 Cost:  19.085932 \n",
      "Prediction:\n",
      " [155.6155  181.46048 181.19853 200.38094 134.98569]\n",
      "550 Cost:  19.000523 \n",
      "Prediction:\n",
      " [155.60059 181.4708  181.19408 200.37683 134.99995]\n",
      "560 Cost:  18.915644 \n",
      "Prediction:\n",
      " [155.58575 181.48103 181.18964 200.3727  135.01418]\n",
      "570 Cost:  18.831242 \n",
      "Prediction:\n",
      " [155.57094 181.49127 181.18523 200.36864 135.02837]\n",
      "580 Cost:  18.747232 \n",
      "Prediction:\n",
      " [155.5562  181.5015  181.18083 200.36455 135.04253]\n",
      "590 Cost:  18.6637 \n",
      "Prediction:\n",
      " [155.54147 181.51166 181.17642 200.36047 135.05664]\n",
      "600 Cost:  18.580511 \n",
      "Prediction:\n",
      " [155.52678 181.52184 181.17204 200.3564  135.07072]\n",
      "610 Cost:  18.497904 \n",
      "Prediction:\n",
      " [155.51213 181.53194 181.16765 200.35234 135.08475]\n",
      "620 Cost:  18.415674 \n",
      "Prediction:\n",
      " [155.49754 181.54204 181.1633  200.34831 135.09877]\n",
      "630 Cost:  18.333868 \n",
      "Prediction:\n",
      " [155.48299 181.55212 181.15895 200.34427 135.11273]\n",
      "640 Cost:  18.252502 \n",
      "Prediction:\n",
      " [155.46846 181.56216 181.15462 200.34024 135.12666]\n",
      "650 Cost:  18.17153 \n",
      "Prediction:\n",
      " [155.45398 181.57219 181.1503  200.33621 135.14056]\n",
      "660 Cost:  18.091034 \n",
      "Prediction:\n",
      " [155.43953 181.58217 181.146   200.3322  135.15442]\n",
      "670 Cost:  18.010988 \n",
      "Prediction:\n",
      " [155.42514 181.59212 181.1417  200.3282  135.16824]\n",
      "680 Cost:  17.931284 \n",
      "Prediction:\n",
      " [155.41078 181.60208 181.13742 200.32423 135.18205]\n",
      "690 Cost:  17.852083 \n",
      "Prediction:\n",
      " [155.39645 181.61197 181.13313 200.32024 135.19579]\n",
      "700 Cost:  17.773285 \n",
      "Prediction:\n",
      " [155.3822  181.62187 181.1289  200.31628 135.20952]\n",
      "710 Cost:  17.694866 \n",
      "Prediction:\n",
      " [155.36795 181.63171 181.12463 200.3123  135.22319]\n",
      "720 Cost:  17.616964 \n",
      "Prediction:\n",
      " [155.35376 181.64153 181.1204  200.30836 135.23683]\n",
      "730 Cost:  17.53934 \n",
      "Prediction:\n",
      " [155.33958 181.65132 181.11618 200.3044  135.25044]\n",
      "740 Cost:  17.462204 \n",
      "Prediction:\n",
      " [155.32547 181.6611  181.11197 200.30046 135.264  ]\n",
      "750 Cost:  17.38545 \n",
      "Prediction:\n",
      " [155.31139 181.67084 181.10774 200.29652 135.27754]\n",
      "760 Cost:  17.309103 \n",
      "Prediction:\n",
      " [155.29733 181.68054 181.10355 200.2926  135.29105]\n",
      "770 Cost:  17.23318 \n",
      "Prediction:\n",
      " [155.28333 181.69026 181.0994  200.28873 135.30452]\n",
      "780 Cost:  17.157688 \n",
      "Prediction:\n",
      " [155.26936 181.6999  181.09521 200.2848  135.31793]\n",
      "790 Cost:  17.0825 \n",
      "Prediction:\n",
      " [155.25545 181.70956 181.0911  200.28093 135.33136]\n",
      "800 Cost:  17.007786 \n",
      "Prediction:\n",
      " [155.24158 181.71918 181.08694 200.27705 135.34473]\n",
      "810 Cost:  16.933466 \n",
      "Prediction:\n",
      " [155.22772 181.72876 181.08281 200.27316 135.35803]\n",
      "820 Cost:  16.859539 \n",
      "Prediction:\n",
      " [155.21391 181.7383  181.07869 200.26929 135.37132]\n",
      "830 Cost:  16.785969 \n",
      "Prediction:\n",
      " [155.20013 181.74783 181.07457 200.26541 135.38457]\n",
      "840 Cost:  16.71284 \n",
      "Prediction:\n",
      " [155.1864  181.75732 181.07048 200.26158 135.3978 ]\n",
      "850 Cost:  16.64004 \n",
      "Prediction:\n",
      " [155.17268 181.7668  181.06639 200.25774 135.41098]\n",
      "860 Cost:  16.56767 \n",
      "Prediction:\n",
      " [155.15906 181.77629 181.06236 200.25394 135.42415]\n",
      "870 Cost:  16.495632 \n",
      "Prediction:\n",
      " [155.14542 181.7857  181.05827 200.25009 135.43726]\n",
      "880 Cost:  16.424044 \n",
      "Prediction:\n",
      " [155.13185 181.7951  181.05424 200.24629 135.45035]\n",
      "890 Cost:  16.352783 \n",
      "Prediction:\n",
      " [155.11829 181.80446 181.05019 200.24248 135.4634 ]\n",
      "900 Cost:  16.28188 \n",
      "Prediction:\n",
      " [155.1048  181.81383 181.04619 200.23868 135.47643]\n",
      "910 Cost:  16.211412 \n",
      "Prediction:\n",
      " [155.09132 181.82314 181.04214 200.23486 135.48938]\n",
      "920 Cost:  16.141285 \n",
      "Prediction:\n",
      " [155.07788 181.83243 181.03815 200.2311  135.50233]\n",
      "930 Cost:  16.071537 \n",
      "Prediction:\n",
      " [155.0645  181.84172 181.03418 200.22734 135.51526]\n",
      "940 Cost:  16.002163 \n",
      "Prediction:\n",
      " [155.05113 181.85095 181.03018 200.22356 135.52812]\n",
      "950 Cost:  15.9331875 \n",
      "Prediction:\n",
      " [155.03784 181.86018 181.02623 200.21983 135.54099]\n",
      "960 Cost:  15.864508 \n",
      "Prediction:\n",
      " [155.02454 181.86937 181.02226 200.21606 135.55379]\n",
      "970 Cost:  15.796232 \n",
      "Prediction:\n",
      " [155.01129 181.87854 181.01833 200.21234 135.56657]\n",
      "980 Cost:  15.728277 \n",
      "Prediction:\n",
      " [154.99808 181.88768 181.01439 200.20859 135.57932]\n",
      "990 Cost:  15.660688 \n",
      "Prediction:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [154.9849  181.8968  181.01045 200.20486 135.59203]\n",
      "1000 Cost:  15.593515 \n",
      "Prediction:\n",
      " [154.97179 181.9059  181.00656 200.20117 135.60472]\n",
      "1010 Cost:  15.526629 \n",
      "Prediction:\n",
      " [154.95868 181.91498 181.00267 200.19746 135.61737]\n",
      "1020 Cost:  15.460217 \n",
      "Prediction:\n",
      " [154.94563 181.92401 180.99878 200.19379 135.62997]\n",
      "1030 Cost:  15.394046 \n",
      "Prediction:\n",
      " [154.9326  181.93303 180.99489 200.19008 135.64255]\n",
      "1040 Cost:  15.328229 \n",
      "Prediction:\n",
      " [154.9196  181.94203 180.99103 200.18642 135.6551 ]\n",
      "1050 Cost:  15.262744 \n",
      "Prediction:\n",
      " [154.90665 181.951   180.98717 200.18272 135.66762]\n",
      "1060 Cost:  15.197647 \n",
      "Prediction:\n",
      " [154.89374 181.95995 180.98334 200.17908 135.68011]\n",
      "1070 Cost:  15.132868 \n",
      "Prediction:\n",
      " [154.88086 181.96887 180.9795  200.17542 135.69257]\n",
      "1080 Cost:  15.068486 \n",
      "Prediction:\n",
      " [154.868   181.97775 180.97568 200.17175 135.70496]\n",
      "1090 Cost:  15.004419 \n",
      "Prediction:\n",
      " [154.8552  181.98662 180.97186 200.16812 135.71735]\n",
      "1100 Cost:  14.940659 \n",
      "Prediction:\n",
      " [154.84242 181.99547 180.96806 200.16449 135.7297 ]\n",
      "1110 Cost:  14.877268 \n",
      "Prediction:\n",
      " [154.8297  182.0043  180.96428 200.16089 135.74203]\n",
      "1120 Cost:  14.814151 \n",
      "Prediction:\n",
      " [154.81699 182.01309 180.96048 200.15724 135.75432]\n",
      "1130 Cost:  14.751413 \n",
      "Prediction:\n",
      " [154.80432 182.02188 180.95674 200.15366 135.76659]\n",
      "1140 Cost:  14.689035 \n",
      "Prediction:\n",
      " [154.79167 182.0306  180.95296 200.15004 135.7788 ]\n",
      "1150 Cost:  14.626935 \n",
      "Prediction:\n",
      " [154.77907 182.03934 180.9492  200.14645 135.79099]\n",
      "1160 Cost:  14.565218 \n",
      "Prediction:\n",
      " [154.76651 182.04803 180.94548 200.14288 135.80315]\n",
      "1170 Cost:  14.503775 \n",
      "Prediction:\n",
      " [154.754   182.05672 180.94177 200.13931 135.81529]\n",
      "1180 Cost:  14.44266 \n",
      "Prediction:\n",
      " [154.7415  182.06537 180.93803 200.13573 135.82738]\n",
      "1190 Cost:  14.381864 \n",
      "Prediction:\n",
      " [154.72903 182.074   180.93434 200.13217 135.83945]\n",
      "1200 Cost:  14.321416 \n",
      "Prediction:\n",
      " [154.71661 182.08261 180.93065 200.12863 135.85149]\n",
      "1210 Cost:  14.261249 \n",
      "Prediction:\n",
      " [154.70422 182.09119 180.92697 200.12508 135.8635 ]\n",
      "1220 Cost:  14.201416 \n",
      "Prediction:\n",
      " [154.69188 182.09976 180.9233  200.12155 135.87547]\n",
      "1230 Cost:  14.141975 \n",
      "Prediction:\n",
      " [154.67957 182.10828 180.91963 200.11801 135.88739]\n",
      "1240 Cost:  14.08275 \n",
      "Prediction:\n",
      " [154.66727 182.11678 180.91597 200.11449 135.8993 ]\n",
      "1250 Cost:  14.023895 \n",
      "Prediction:\n",
      " [154.65503 182.12529 180.91235 200.11101 135.9112 ]\n",
      "1260 Cost:  13.965311 \n",
      "Prediction:\n",
      " [154.6428  182.13374 180.90872 200.10748 135.92303]\n",
      "1270 Cost:  13.907028 \n",
      "Prediction:\n",
      " [154.63063 182.14218 180.9051  200.104   135.93488]\n",
      "1280 Cost:  13.84908 \n",
      "Prediction:\n",
      " [154.61847 182.15059 180.90147 200.1005  135.94664]\n",
      "1290 Cost:  13.79144 \n",
      "Prediction:\n",
      " [154.60637 182.159   180.89789 200.09703 135.9584 ]\n",
      "1300 Cost:  13.734057 \n",
      "Prediction:\n",
      " [154.59427 182.16736 180.89429 200.09354 135.97012]\n",
      "1310 Cost:  13.67706 \n",
      "Prediction:\n",
      " [154.58224 182.17572 180.89073 200.0901  135.98183]\n",
      "1320 Cost:  13.620288 \n",
      "Prediction:\n",
      " [154.57022 182.18404 180.88715 200.08662 135.99348]\n",
      "1330 Cost:  13.563815 \n",
      "Prediction:\n",
      " [154.55824 182.19235 180.8836  200.08318 136.00513]\n",
      "1340 Cost:  13.507672 \n",
      "Prediction:\n",
      " [154.5463  182.20062 180.88004 200.07973 136.01672]\n",
      "1350 Cost:  13.451818 \n",
      "Prediction:\n",
      " [154.53436 182.20888 180.8765  200.0763  136.02829]\n",
      "1360 Cost:  13.39626 \n",
      "Prediction:\n",
      " [154.5225  182.2171  180.87299 200.07288 136.03986]\n",
      "1370 Cost:  13.340962 \n",
      "Prediction:\n",
      " [154.51065 182.22533 180.86946 200.06944 136.05136]\n",
      "1380 Cost:  13.28602 \n",
      "Prediction:\n",
      " [154.49883 182.2335  180.86595 200.06604 136.06284]\n",
      "1390 Cost:  13.231344 \n",
      "Prediction:\n",
      " [154.48706 182.24167 180.86247 200.06264 136.0743 ]\n",
      "1400 Cost:  13.176892 \n",
      "Prediction:\n",
      " [154.4753  182.24982 180.85896 200.05923 136.08572]\n",
      "1410 Cost:  13.122777 \n",
      "Prediction:\n",
      " [154.4636  182.25793 180.8555  200.05582 136.0971 ]\n",
      "1420 Cost:  13.0689945 \n",
      "Prediction:\n",
      " [154.4519  182.26602 180.85202 200.05244 136.10846]\n",
      "1430 Cost:  13.015384 \n",
      "Prediction:\n",
      " [154.44026 182.27412 180.84859 200.04909 136.11983]\n",
      "1440 Cost:  12.962158 \n",
      "Prediction:\n",
      " [154.42863 182.28215 180.84512 200.04572 136.13112]\n",
      "1450 Cost:  12.909177 \n",
      "Prediction:\n",
      " [154.41704 182.29018 180.84167 200.04234 136.14238]\n",
      "1460 Cost:  12.856476 \n",
      "Prediction:\n",
      " [154.40549 182.2982  180.83826 200.039   136.15363]\n",
      "1470 Cost:  12.804006 \n",
      "Prediction:\n",
      " [154.394   182.3062  180.83484 200.03566 136.16487]\n",
      "1480 Cost:  12.751862 \n",
      "Prediction:\n",
      " [154.38248 182.31413 180.83142 200.0323  136.17604]\n",
      "1490 Cost:  12.699963 \n",
      "Prediction:\n",
      " [154.37102 182.32208 180.82802 200.02896 136.1872 ]\n",
      "1500 Cost:  12.648378 \n",
      "Prediction:\n",
      " [154.3596  182.33002 180.82465 200.02567 136.19833]\n",
      "1510 Cost:  12.5970545 \n",
      "Prediction:\n",
      " [154.34822 182.3379  180.82127 200.02235 136.20944]\n",
      "1520 Cost:  12.545962 \n",
      "Prediction:\n",
      " [154.33685 182.34576 180.81789 200.01901 136.2205 ]\n",
      "1530 Cost:  12.4952135 \n",
      "Prediction:\n",
      " [154.32552 182.35362 180.81453 200.01573 136.23154]\n",
      "1540 Cost:  12.444662 \n",
      "Prediction:\n",
      " [154.31424 182.36148 180.8112  200.01245 136.24257]\n",
      "1550 Cost:  12.394404 \n",
      "Prediction:\n",
      " [154.30296 182.3693  180.80786 200.00916 136.25354]\n",
      "1560 Cost:  12.344364 \n",
      "Prediction:\n",
      " [154.29173 182.37706 180.8045  200.00586 136.26451]\n",
      "1570 Cost:  12.294657 \n",
      "Prediction:\n",
      " [154.28052 182.38484 180.8012  200.0026  136.27542]\n",
      "1580 Cost:  12.245176 \n",
      "Prediction:\n",
      " [154.26936 182.39258 180.7979  199.99934 136.28635]\n",
      "1590 Cost:  12.195913 \n",
      "Prediction:\n",
      " [154.25821 182.40031 180.79459 199.99606 136.29721]\n",
      "1600 Cost:  12.14694 \n",
      "Prediction:\n",
      " [154.2471  182.40802 180.79129 199.99281 136.30806]\n",
      "1610 Cost:  12.098246 \n",
      "Prediction:\n",
      " [154.23604 182.41571 180.78802 199.9896  136.3189 ]\n",
      "1620 Cost:  12.049826 \n",
      "Prediction:\n",
      " [154.22499 182.42336 180.78474 199.98634 136.32967]\n",
      "1630 Cost:  12.001604 \n",
      "Prediction:\n",
      " [154.21396 182.431   180.78146 199.98311 136.34042]\n",
      "1640 Cost:  11.953644 \n",
      "Prediction:\n",
      " [154.20297 182.43863 180.77821 199.97987 136.35115]\n",
      "1650 Cost:  11.905985 \n",
      "Prediction:\n",
      " [154.19203 182.44621 180.77498 199.97667 136.36186]\n",
      "1660 Cost:  11.85854 \n",
      "Prediction:\n",
      " [154.18109 182.45378 180.77173 199.97345 136.37253]\n",
      "1670 Cost:  11.811293 \n",
      "Prediction:\n",
      " [154.1702  182.46135 180.76851 199.97025 136.3832 ]\n",
      "1680 Cost:  11.764372 \n",
      "Prediction:\n",
      " [154.15935 182.46889 180.7653  199.96706 136.39381]\n",
      "1690 Cost:  11.717645 \n",
      "Prediction:\n",
      " [154.1485  182.4764  180.76208 199.96385 136.4044 ]\n",
      "1700 Cost:  11.671217 \n",
      "Prediction:\n",
      " [154.13771 182.4839  180.7589  199.96068 136.41496]\n",
      "1710 Cost:  11.625004 \n",
      "Prediction:\n",
      " [154.12692 182.49135 180.75569 199.9575  136.4255 ]\n",
      "1720 Cost:  11.579024 \n",
      "Prediction:\n",
      " [154.1162  182.49881 180.75252 199.95433 136.43602]\n",
      "1730 Cost:  11.5333 \n",
      "Prediction:\n",
      " [154.10548 182.50624 180.74934 199.95117 136.4465 ]\n",
      "1740 Cost:  11.487822 \n",
      "Prediction:\n",
      " [154.09479 182.51366 180.74619 199.94803 136.45695]\n",
      "1750 Cost:  11.442566 \n",
      "Prediction:\n",
      " [154.08415 182.52106 180.74304 199.94489 136.46739]\n",
      "1760 Cost:  11.397519 \n",
      "Prediction:\n",
      " [154.07353 182.52844 180.73991 199.94176 136.47781]\n",
      "1770 Cost:  11.35274 \n",
      "Prediction:\n",
      " [154.06293 182.53577 180.73676 199.9386  136.48817]\n",
      "1780 Cost:  11.308195 \n",
      "Prediction:\n",
      " [154.05235 182.54309 180.73363 199.93547 136.49852]\n",
      "1790 Cost:  11.263849 \n",
      "Prediction:\n",
      " [154.04184 182.55042 180.73053 199.93236 136.50887]\n",
      "1800 Cost:  11.219816 \n",
      "Prediction:\n",
      " [154.03133 182.55771 180.72743 199.92924 136.51913]\n",
      "1810 Cost:  11.17596 \n",
      "Prediction:\n",
      " [154.02084 182.56496 180.7243  199.92613 136.5294 ]\n",
      "1820 Cost:  11.13233 \n",
      "Prediction:\n",
      " [154.0104  182.5722  180.72124 199.92303 136.53966]\n",
      "1830 Cost:  11.088928 \n",
      "Prediction:\n",
      " [154.      182.57945 180.71817 199.91995 136.54988]\n",
      "1840 Cost:  11.045772 \n",
      "Prediction:\n",
      " [153.9896  182.58664 180.71506 199.91684 136.56004]\n",
      "1850 Cost:  11.002822 \n",
      "Prediction:\n",
      " [153.97925 182.59384 180.71202 199.91377 136.57022]\n",
      "1860 Cost:  10.9601 \n",
      "Prediction:\n",
      " [153.96893 182.60101 180.70897 199.9107  136.58037]\n",
      "1870 Cost:  10.917595 \n",
      "Prediction:\n",
      " [153.95862 182.60815 180.70592 199.90762 136.59047]\n",
      "1880 Cost:  10.875308 \n",
      "Prediction:\n",
      " [153.94833 182.6153  180.70288 199.90457 136.60056]\n",
      "1890 Cost:  10.833259 \n",
      "Prediction:\n",
      " [153.9381  182.62239 180.69986 199.9015  136.61061]\n",
      "1900 Cost:  10.791432 \n",
      "Prediction:\n",
      " [153.92789 182.6295  180.69684 199.89848 136.62065]\n",
      "1910 Cost:  10.7498045 \n",
      "Prediction:\n",
      " [153.91771 182.63657 180.69383 199.89543 136.63066]\n",
      "1920 Cost:  10.708422 \n",
      "Prediction:\n",
      " [153.90753 182.64359 180.69081 199.89238 136.64062]\n",
      "1930 Cost:  10.667209 \n",
      "Prediction:\n",
      " [153.89743 182.65063 180.68785 199.88936 136.6506 ]\n",
      "1940 Cost:  10.626253 \n",
      "Prediction:\n",
      " [153.88733 182.65765 180.68486 199.88634 136.66052]\n",
      "1950 Cost:  10.585493 \n",
      "Prediction:\n",
      " [153.87724 182.66463 180.68187 199.88332 136.67043]\n",
      "1960 Cost:  10.54497 \n",
      "Prediction:\n",
      " [153.8672  182.6716  180.67891 199.88031 136.6803 ]\n",
      "1970 Cost:  10.504617 \n",
      "Prediction:\n",
      " [153.8572  182.67856 180.67596 199.87732 136.69017]\n",
      "1980 Cost:  10.464464 \n",
      "Prediction:\n",
      " [153.8472  182.6855  180.673   199.87431 136.7    ]\n",
      "1990 Cost:  10.424598 \n",
      "Prediction:\n",
      " [153.83725 182.69241 180.67007 199.87134 136.7098 ]\n",
      "2000 Cost:  10.3849125 \n",
      "Prediction:\n",
      " [153.82732 182.6993  180.66713 199.86835 136.71956]\n"
     ]
    }
   ],
   "source": [
    "#Multi-variable regression 다변수회귀\n",
    "\n",
    "x1_data = [73., 93., 89., 96., 73.]\n",
    "x2_data = [80., 88., 91., 98., 66.]\n",
    "x3_data = [75., 93., 90., 100., 70.]\n",
    "\n",
    "y_data = [152., 185., 180., 196., 142.]\n",
    "\n",
    "x1 = tf.placeholder(tf.float32)\n",
    "x2 = tf.placeholder(tf.float32)\n",
    "x3 = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([1]), name='weight1')\n",
    "w2 = tf.Variable(tf.random_normal([1]), name='weight2')\n",
    "w3 = tf.Variable(tf.random_normal([1]), name='weight3')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = x1 * w1 + x2 * w2 + x3 * w3 + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n",
    "                                   feed_dict={x1: x1_data, x2: x2_data, x3: x3_data, Y: y_data})\n",
    "    if step % 10 == 0:\n",
    "        print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  1513.0605 \n",
      "Prediction:\n",
      " [[186.32188]\n",
      " [225.86519]\n",
      " [221.60562]\n",
      " [241.06027]\n",
      " [172.9175 ]]\n",
      "10 Cost:  0.36904773 \n",
      "Prediction:\n",
      " [[151.91473]\n",
      " [184.51285]\n",
      " [180.85918]\n",
      " [196.68843]\n",
      " [141.37668]]\n",
      "20 Cost:  0.3544977 \n",
      "Prediction:\n",
      " [[151.80931]\n",
      " [184.38866]\n",
      " [180.7355 ]\n",
      " [196.55379]\n",
      " [141.28255]]\n",
      "30 Cost:  0.35379815 \n",
      "Prediction:\n",
      " [[151.8077 ]\n",
      " [184.38918]\n",
      " [180.73473]\n",
      " [196.55298]\n",
      " [141.28355]]\n",
      "40 Cost:  0.35311106 \n",
      "Prediction:\n",
      " [[151.8064 ]\n",
      " [184.3901 ]\n",
      " [180.73436]\n",
      " [196.55261]\n",
      " [141.28485]]\n",
      "50 Cost:  0.3524279 \n",
      "Prediction:\n",
      " [[151.80508]\n",
      " [184.39099]\n",
      " [180.73398]\n",
      " [196.5522 ]\n",
      " [141.28613]]\n",
      "60 Cost:  0.35174352 \n",
      "Prediction:\n",
      " [[151.80376]\n",
      " [184.3919 ]\n",
      " [180.73358]\n",
      " [196.5518 ]\n",
      " [141.2874 ]]\n",
      "70 Cost:  0.35106117 \n",
      "Prediction:\n",
      " [[151.80247]\n",
      " [184.3928 ]\n",
      " [180.7332 ]\n",
      " [196.5514 ]\n",
      " [141.28868]]\n",
      "80 Cost:  0.35038087 \n",
      "Prediction:\n",
      " [[151.80118]\n",
      " [184.3937 ]\n",
      " [180.73282]\n",
      " [196.55103]\n",
      " [141.28998]]\n",
      "90 Cost:  0.34971422 \n",
      "Prediction:\n",
      " [[151.7999 ]\n",
      " [184.3946 ]\n",
      " [180.73245]\n",
      " [196.55064]\n",
      " [141.29124]]\n",
      "100 Cost:  0.34904996 \n",
      "Prediction:\n",
      " [[151.7986 ]\n",
      " [184.39548]\n",
      " [180.73206]\n",
      " [196.55025]\n",
      " [141.2925 ]]\n",
      "110 Cost:  0.34838307 \n",
      "Prediction:\n",
      " [[151.79732]\n",
      " [184.3964 ]\n",
      " [180.73169]\n",
      " [196.54987]\n",
      " [141.29376]]\n",
      "120 Cost:  0.34770748 \n",
      "Prediction:\n",
      " [[151.79605]\n",
      " [184.39728]\n",
      " [180.7313 ]\n",
      " [196.54947]\n",
      " [141.29504]]\n",
      "130 Cost:  0.3470562 \n",
      "Prediction:\n",
      " [[151.79475]\n",
      " [184.39815]\n",
      " [180.73091]\n",
      " [196.54909]\n",
      " [141.2963 ]]\n",
      "140 Cost:  0.34639573 \n",
      "Prediction:\n",
      " [[151.7935 ]\n",
      " [184.39905]\n",
      " [180.73055]\n",
      " [196.5487 ]\n",
      " [141.29756]]\n",
      "150 Cost:  0.34574834 \n",
      "Prediction:\n",
      " [[151.79222]\n",
      " [184.39993]\n",
      " [180.73018]\n",
      " [196.54831]\n",
      " [141.2988 ]]\n",
      "160 Cost:  0.34509537 \n",
      "Prediction:\n",
      " [[151.79095]\n",
      " [184.4008 ]\n",
      " [180.7298 ]\n",
      " [196.54793]\n",
      " [141.30006]]\n",
      "170 Cost:  0.34444898 \n",
      "Prediction:\n",
      " [[151.78969]\n",
      " [184.40169]\n",
      " [180.72942]\n",
      " [196.54755]\n",
      " [141.3013 ]]\n",
      "180 Cost:  0.3438037 \n",
      "Prediction:\n",
      " [[151.78842]\n",
      " [184.40256]\n",
      " [180.72903]\n",
      " [196.54716]\n",
      " [141.30255]]\n",
      "190 Cost:  0.3431706 \n",
      "Prediction:\n",
      " [[151.78719]\n",
      " [184.40343]\n",
      " [180.72868]\n",
      " [196.54678]\n",
      " [141.30379]]\n",
      "200 Cost:  0.34252957 \n",
      "Prediction:\n",
      " [[151.78592]\n",
      " [184.4043 ]\n",
      " [180.7283 ]\n",
      " [196.54639]\n",
      " [141.30502]]\n",
      "210 Cost:  0.3419003 \n",
      "Prediction:\n",
      " [[151.78467]\n",
      " [184.40515]\n",
      " [180.72794]\n",
      " [196.546  ]\n",
      " [141.30626]]\n",
      "220 Cost:  0.3412683 \n",
      "Prediction:\n",
      " [[151.78343]\n",
      " [184.40604]\n",
      " [180.72757]\n",
      " [196.54562]\n",
      " [141.30748]]\n",
      "230 Cost:  0.34065366 \n",
      "Prediction:\n",
      " [[151.78218]\n",
      " [184.40688]\n",
      " [180.72722]\n",
      " [196.54526]\n",
      " [141.30872]]\n",
      "240 Cost:  0.34002718 \n",
      "Prediction:\n",
      " [[151.78096]\n",
      " [184.40775]\n",
      " [180.72685]\n",
      " [196.54488]\n",
      " [141.30994]]\n",
      "250 Cost:  0.33941504 \n",
      "Prediction:\n",
      " [[151.77972]\n",
      " [184.4086 ]\n",
      " [180.7265 ]\n",
      " [196.54451]\n",
      " [141.31116]]\n",
      "260 Cost:  0.33879322 \n",
      "Prediction:\n",
      " [[151.77849]\n",
      " [184.40945]\n",
      " [180.72612]\n",
      " [196.54411]\n",
      " [141.31236]]\n",
      "270 Cost:  0.3381799 \n",
      "Prediction:\n",
      " [[151.77725]\n",
      " [184.41031]\n",
      " [180.72575]\n",
      " [196.54375]\n",
      " [141.31358]]\n",
      "280 Cost:  0.3375667 \n",
      "Prediction:\n",
      " [[151.77603]\n",
      " [184.41118]\n",
      " [180.7254 ]\n",
      " [196.5434 ]\n",
      " [141.31482]]\n",
      "290 Cost:  0.33696267 \n",
      "Prediction:\n",
      " [[151.77483]\n",
      " [184.41202]\n",
      " [180.72505]\n",
      " [196.54301]\n",
      " [141.31602]]\n",
      "300 Cost:  0.33636135 \n",
      "Prediction:\n",
      " [[151.7736 ]\n",
      " [184.41286]\n",
      " [180.72469]\n",
      " [196.54263]\n",
      " [141.31721]]\n",
      "310 Cost:  0.33576018 \n",
      "Prediction:\n",
      " [[151.7724 ]\n",
      " [184.41371]\n",
      " [180.72433]\n",
      " [196.54227]\n",
      " [141.31842]]\n",
      "320 Cost:  0.33516136 \n",
      "Prediction:\n",
      " [[151.77118]\n",
      " [184.41454]\n",
      " [180.72397]\n",
      " [196.54189]\n",
      " [141.31963]]\n",
      "330 Cost:  0.3345677 \n",
      "Prediction:\n",
      " [[151.76997]\n",
      " [184.41537]\n",
      " [180.72362]\n",
      " [196.5415 ]\n",
      " [141.32082]]\n",
      "340 Cost:  0.33397803 \n",
      "Prediction:\n",
      " [[151.76877]\n",
      " [184.41621]\n",
      " [180.72327]\n",
      " [196.54115]\n",
      " [141.32202]]\n",
      "350 Cost:  0.33338824 \n",
      "Prediction:\n",
      " [[151.76758]\n",
      " [184.41705]\n",
      " [180.7229 ]\n",
      " [196.5408 ]\n",
      " [141.32321]]\n",
      "360 Cost:  0.33280355 \n",
      "Prediction:\n",
      " [[151.76637]\n",
      " [184.4179 ]\n",
      " [180.72256]\n",
      " [196.54042]\n",
      " [141.3244 ]]\n",
      "370 Cost:  0.33222118 \n",
      "Prediction:\n",
      " [[151.76518]\n",
      " [184.41872]\n",
      " [180.7222 ]\n",
      " [196.54005]\n",
      " [141.32558]]\n",
      "380 Cost:  0.33164167 \n",
      "Prediction:\n",
      " [[151.76399]\n",
      " [184.41954]\n",
      " [180.72186]\n",
      " [196.53967]\n",
      " [141.32677]]\n",
      "390 Cost:  0.33106086 \n",
      "Prediction:\n",
      " [[151.76282]\n",
      " [184.42038]\n",
      " [180.72151]\n",
      " [196.53932]\n",
      " [141.32796]]\n",
      "400 Cost:  0.330495 \n",
      "Prediction:\n",
      " [[151.76163]\n",
      " [184.42119]\n",
      " [180.72116]\n",
      " [196.53896]\n",
      " [141.32912]]\n",
      "410 Cost:  0.32992592 \n",
      "Prediction:\n",
      " [[151.76045]\n",
      " [184.42201]\n",
      " [180.72083]\n",
      " [196.53859]\n",
      " [141.33029]]\n",
      "420 Cost:  0.3293586 \n",
      "Prediction:\n",
      " [[151.75926]\n",
      " [184.42282]\n",
      " [180.72046]\n",
      " [196.53822]\n",
      " [141.33145]]\n",
      "430 Cost:  0.32878748 \n",
      "Prediction:\n",
      " [[151.7581 ]\n",
      " [184.42366]\n",
      " [180.72012]\n",
      " [196.53786]\n",
      " [141.33263]]\n",
      "440 Cost:  0.32822958 \n",
      "Prediction:\n",
      " [[151.75693]\n",
      " [184.42447]\n",
      " [180.71979]\n",
      " [196.5375 ]\n",
      " [141.3338 ]]\n",
      "450 Cost:  0.32767272 \n",
      "Prediction:\n",
      " [[151.75575]\n",
      " [184.42526]\n",
      " [180.71942]\n",
      " [196.53714]\n",
      " [141.33495]]\n",
      "460 Cost:  0.32711706 \n",
      "Prediction:\n",
      " [[151.7546 ]\n",
      " [184.42607]\n",
      " [180.71909]\n",
      " [196.53677]\n",
      " [141.3361 ]]\n",
      "470 Cost:  0.32656774 \n",
      "Prediction:\n",
      " [[151.75343]\n",
      " [184.4269 ]\n",
      " [180.71877]\n",
      " [196.5364 ]\n",
      " [141.33725]]\n",
      "480 Cost:  0.326014 \n",
      "Prediction:\n",
      " [[151.75227]\n",
      " [184.42769]\n",
      " [180.71841]\n",
      " [196.53604]\n",
      " [141.33841]]\n",
      "490 Cost:  0.32547534 \n",
      "Prediction:\n",
      " [[151.75113]\n",
      " [184.4285 ]\n",
      " [180.7181 ]\n",
      " [196.53572]\n",
      " [141.33957]]\n",
      "500 Cost:  0.3249226 \n",
      "Prediction:\n",
      " [[151.74998]\n",
      " [184.42929]\n",
      " [180.71773]\n",
      " [196.53535]\n",
      " [141.34071]]\n",
      "510 Cost:  0.32438993 \n",
      "Prediction:\n",
      " [[151.74883]\n",
      " [184.43008]\n",
      " [180.7174 ]\n",
      " [196.53499]\n",
      " [141.34184]]\n",
      "520 Cost:  0.32384762 \n",
      "Prediction:\n",
      " [[151.74768]\n",
      " [184.43088]\n",
      " [180.71706]\n",
      " [196.53464]\n",
      " [141.34299]]\n",
      "530 Cost:  0.32331184 \n",
      "Prediction:\n",
      " [[151.74654]\n",
      " [184.43167]\n",
      " [180.71672]\n",
      " [196.53427]\n",
      " [141.34412]]\n",
      "540 Cost:  0.3227856 \n",
      "Prediction:\n",
      " [[151.74542]\n",
      " [184.43246]\n",
      " [180.71642]\n",
      " [196.53394]\n",
      " [141.34526]]\n",
      "550 Cost:  0.32224822 \n",
      "Prediction:\n",
      " [[151.74428]\n",
      " [184.43326]\n",
      " [180.71606]\n",
      " [196.53357]\n",
      " [141.34639]]\n",
      "560 Cost:  0.3217141 \n",
      "Prediction:\n",
      " [[151.74315]\n",
      " [184.43404]\n",
      " [180.71571]\n",
      " [196.5332 ]\n",
      " [141.34752]]\n",
      "570 Cost:  0.32119313 \n",
      "Prediction:\n",
      " [[151.74202]\n",
      " [184.43483]\n",
      " [180.7154 ]\n",
      " [196.53287]\n",
      " [141.34865]]\n",
      "580 Cost:  0.3206744 \n",
      "Prediction:\n",
      " [[151.74089]\n",
      " [184.43561]\n",
      " [180.71507]\n",
      " [196.5325 ]\n",
      " [141.34976]]\n",
      "590 Cost:  0.3201502 \n",
      "Prediction:\n",
      " [[151.73978]\n",
      " [184.4364 ]\n",
      " [180.71474]\n",
      " [196.53217]\n",
      " [141.35089]]\n",
      "600 Cost:  0.31962982 \n",
      "Prediction:\n",
      " [[151.73865]\n",
      " [184.43718]\n",
      " [180.7144 ]\n",
      " [196.5318 ]\n",
      " [141.352  ]]\n",
      "610 Cost:  0.3191274 \n",
      "Prediction:\n",
      " [[151.73753]\n",
      " [184.43794]\n",
      " [180.71408]\n",
      " [196.53146]\n",
      " [141.3531 ]]\n",
      "620 Cost:  0.31860974 \n",
      "Prediction:\n",
      " [[151.73643]\n",
      " [184.43872]\n",
      " [180.71375]\n",
      " [196.53111]\n",
      " [141.35422]]\n",
      "630 Cost:  0.31810278 \n",
      "Prediction:\n",
      " [[151.73532]\n",
      " [184.43948]\n",
      " [180.71342]\n",
      " [196.53076]\n",
      " [141.35533]]\n",
      "640 Cost:  0.3175919 \n",
      "Prediction:\n",
      " [[151.73422]\n",
      " [184.44028]\n",
      " [180.7131 ]\n",
      " [196.53043]\n",
      " [141.35645]]\n",
      "650 Cost:  0.3170949 \n",
      "Prediction:\n",
      " [[151.73311]\n",
      " [184.44102]\n",
      " [180.71278]\n",
      " [196.53008]\n",
      " [141.35754]]\n",
      "660 Cost:  0.31658977 \n",
      "Prediction:\n",
      " [[151.73201]\n",
      " [184.44179]\n",
      " [180.71245]\n",
      " [196.52972]\n",
      " [141.35864]]\n",
      "670 Cost:  0.31609762 \n",
      "Prediction:\n",
      " [[151.73091]\n",
      " [184.44254]\n",
      " [180.71213]\n",
      " [196.52937]\n",
      " [141.35973]]\n",
      "680 Cost:  0.31559762 \n",
      "Prediction:\n",
      " [[151.72983]\n",
      " [184.44331]\n",
      " [180.7118 ]\n",
      " [196.52904]\n",
      " [141.36082]]\n",
      "690 Cost:  0.31510463 \n",
      "Prediction:\n",
      " [[151.72873]\n",
      " [184.44408]\n",
      " [180.71149]\n",
      " [196.52869]\n",
      " [141.36191]]\n",
      "700 Cost:  0.31461057 \n",
      "Prediction:\n",
      " [[151.72765]\n",
      " [184.44484]\n",
      " [180.71117]\n",
      " [196.52835]\n",
      " [141.363  ]]\n",
      "710 Cost:  0.31412548 \n",
      "Prediction:\n",
      " [[151.72656]\n",
      " [184.44559]\n",
      " [180.71086]\n",
      " [196.52802]\n",
      " [141.3641 ]]\n",
      "720 Cost:  0.31364188 \n",
      "Prediction:\n",
      " [[151.72548]\n",
      " [184.44633]\n",
      " [180.71054]\n",
      " [196.52766]\n",
      " [141.36517]]\n",
      "730 Cost:  0.31315884 \n",
      "Prediction:\n",
      " [[151.7244 ]\n",
      " [184.44708]\n",
      " [180.71022]\n",
      " [196.52733]\n",
      " [141.36626]]\n",
      "740 Cost:  0.31268373 \n",
      "Prediction:\n",
      " [[151.72333]\n",
      " [184.44781]\n",
      " [180.70992]\n",
      " [196.52698]\n",
      " [141.36732]]\n",
      "750 Cost:  0.3121981 \n",
      "Prediction:\n",
      " [[151.72226]\n",
      " [184.44858]\n",
      " [180.7096 ]\n",
      " [196.52664]\n",
      " [141.36841]]\n",
      "760 Cost:  0.3117273 \n",
      "Prediction:\n",
      " [[151.7212 ]\n",
      " [184.44933]\n",
      " [180.7093 ]\n",
      " [196.52632]\n",
      " [141.36949]]\n",
      "770 Cost:  0.31125507 \n",
      "Prediction:\n",
      " [[151.72011]\n",
      " [184.45006]\n",
      " [180.70897]\n",
      " [196.52596]\n",
      " [141.37053]]\n",
      "780 Cost:  0.31078234 \n",
      "Prediction:\n",
      " [[151.71906]\n",
      " [184.4508 ]\n",
      " [180.70866]\n",
      " [196.52563]\n",
      " [141.37161]]\n",
      "790 Cost:  0.31031862 \n",
      "Prediction:\n",
      " [[151.718  ]\n",
      " [184.45154]\n",
      " [180.70836]\n",
      " [196.5253 ]\n",
      " [141.37267]]\n",
      "800 Cost:  0.30984458 \n",
      "Prediction:\n",
      " [[151.71695]\n",
      " [184.45229]\n",
      " [180.70804]\n",
      " [196.52496]\n",
      " [141.37373]]\n",
      "810 Cost:  0.30937958 \n",
      "Prediction:\n",
      " [[151.7159 ]\n",
      " [184.453  ]\n",
      " [180.70773]\n",
      " [196.52461]\n",
      " [141.3748 ]]\n",
      "820 Cost:  0.3089146 \n",
      "Prediction:\n",
      " [[151.71484]\n",
      " [184.45374]\n",
      " [180.7074 ]\n",
      " [196.52428]\n",
      " [141.37584]]\n",
      "830 Cost:  0.30846033 \n",
      "Prediction:\n",
      " [[151.71379]\n",
      " [184.45448]\n",
      " [180.70712]\n",
      " [196.52396]\n",
      " [141.3769 ]]\n",
      "840 Cost:  0.30800375 \n",
      "Prediction:\n",
      " [[151.71275]\n",
      " [184.45518]\n",
      " [180.7068 ]\n",
      " [196.5236 ]\n",
      " [141.37794]]\n",
      "850 Cost:  0.30755034 \n",
      "Prediction:\n",
      " [[151.7117 ]\n",
      " [184.45592]\n",
      " [180.7065 ]\n",
      " [196.52328]\n",
      " [141.379  ]]\n",
      "860 Cost:  0.30710024 \n",
      "Prediction:\n",
      " [[151.71066]\n",
      " [184.45663]\n",
      " [180.70619]\n",
      " [196.52295]\n",
      " [141.38004]]\n",
      "870 Cost:  0.3066475 \n",
      "Prediction:\n",
      " [[151.70963]\n",
      " [184.45735]\n",
      " [180.70589]\n",
      " [196.52261]\n",
      " [141.38109]]\n",
      "880 Cost:  0.30619705 \n",
      "Prediction:\n",
      " [[151.70862]\n",
      " [184.4581 ]\n",
      " [180.7056 ]\n",
      " [196.5223 ]\n",
      " [141.38213]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "890 Cost:  0.30576244 \n",
      "Prediction:\n",
      " [[151.70757]\n",
      " [184.4588 ]\n",
      " [180.70529]\n",
      " [196.52197]\n",
      " [141.38315]]\n",
      "900 Cost:  0.30531627 \n",
      "Prediction:\n",
      " [[151.70654]\n",
      " [184.45952]\n",
      " [180.705  ]\n",
      " [196.52162]\n",
      " [141.38419]]\n",
      "910 Cost:  0.3048802 \n",
      "Prediction:\n",
      " [[151.70552]\n",
      " [184.46024]\n",
      " [180.7047 ]\n",
      " [196.52132]\n",
      " [141.38521]]\n",
      "920 Cost:  0.30443528 \n",
      "Prediction:\n",
      " [[151.7045 ]\n",
      " [184.46094]\n",
      " [180.70439]\n",
      " [196.52097]\n",
      " [141.38625]]\n",
      "930 Cost:  0.30399695 \n",
      "Prediction:\n",
      " [[151.70349]\n",
      " [184.46167]\n",
      " [180.7041 ]\n",
      " [196.52066]\n",
      " [141.38728]]\n",
      "940 Cost:  0.3035682 \n",
      "Prediction:\n",
      " [[151.70247]\n",
      " [184.46236]\n",
      " [180.7038 ]\n",
      " [196.52032]\n",
      " [141.38829]]\n",
      "950 Cost:  0.30313355 \n",
      "Prediction:\n",
      " [[151.70145]\n",
      " [184.46306]\n",
      " [180.70349]\n",
      " [196.51999]\n",
      " [141.38931]]\n",
      "960 Cost:  0.3027067 \n",
      "Prediction:\n",
      " [[151.70044]\n",
      " [184.46378]\n",
      " [180.70322]\n",
      " [196.51967]\n",
      " [141.39034]]\n",
      "970 Cost:  0.30227327 \n",
      "Prediction:\n",
      " [[151.69945]\n",
      " [184.46446]\n",
      " [180.7029 ]\n",
      " [196.51933]\n",
      " [141.39134]]\n",
      "980 Cost:  0.30185503 \n",
      "Prediction:\n",
      " [[151.69844]\n",
      " [184.46516]\n",
      " [180.70262]\n",
      " [196.51903]\n",
      " [141.39236]]\n",
      "990 Cost:  0.3014309 \n",
      "Prediction:\n",
      " [[151.69743]\n",
      " [184.46587]\n",
      " [180.70233]\n",
      " [196.51869]\n",
      " [141.39337]]\n",
      "1000 Cost:  0.30100554 \n",
      "Prediction:\n",
      " [[151.69644]\n",
      " [184.46657]\n",
      " [180.70204]\n",
      " [196.51837]\n",
      " [141.3944 ]]\n",
      "1010 Cost:  0.3005974 \n",
      "Prediction:\n",
      " [[151.69543]\n",
      " [184.46725]\n",
      " [180.70175]\n",
      " [196.51805]\n",
      " [141.39537]]\n",
      "1020 Cost:  0.3001699 \n",
      "Prediction:\n",
      " [[151.69444]\n",
      " [184.46796]\n",
      " [180.70145]\n",
      " [196.51773]\n",
      " [141.3964 ]]\n",
      "1030 Cost:  0.2997626 \n",
      "Prediction:\n",
      " [[151.69345]\n",
      " [184.46864]\n",
      " [180.70117]\n",
      " [196.51741]\n",
      " [141.39738]]\n",
      "1040 Cost:  0.29934415 \n",
      "Prediction:\n",
      " [[151.69246]\n",
      " [184.46933]\n",
      " [180.70087]\n",
      " [196.51709]\n",
      " [141.39839]]\n",
      "1050 Cost:  0.29894266 \n",
      "Prediction:\n",
      " [[151.6915 ]\n",
      " [184.47002]\n",
      " [180.7006 ]\n",
      " [196.51678]\n",
      " [141.39938]]\n",
      "1060 Cost:  0.2985379 \n",
      "Prediction:\n",
      " [[151.6905 ]\n",
      " [184.4707 ]\n",
      " [180.70032]\n",
      " [196.51646]\n",
      " [141.40036]]\n",
      "1070 Cost:  0.29812506 \n",
      "Prediction:\n",
      " [[151.68953]\n",
      " [184.47137]\n",
      " [180.70003]\n",
      " [196.51613]\n",
      " [141.40137]]\n",
      "1080 Cost:  0.29771933 \n",
      "Prediction:\n",
      " [[151.68855]\n",
      " [184.47206]\n",
      " [180.69972]\n",
      " [196.51582]\n",
      " [141.40234]]\n",
      "1090 Cost:  0.29731214 \n",
      "Prediction:\n",
      " [[151.68758]\n",
      " [184.47275]\n",
      " [180.69943]\n",
      " [196.5155 ]\n",
      " [141.40334]]\n",
      "1100 Cost:  0.2969235 \n",
      "Prediction:\n",
      " [[151.6866 ]\n",
      " [184.4734 ]\n",
      " [180.69916]\n",
      " [196.5152 ]\n",
      " [141.40431]]\n",
      "1110 Cost:  0.2965231 \n",
      "Prediction:\n",
      " [[151.68562]\n",
      " [184.47409]\n",
      " [180.69888]\n",
      " [196.51486]\n",
      " [141.40529]]\n",
      "1120 Cost:  0.29612255 \n",
      "Prediction:\n",
      " [[151.68468]\n",
      " [184.47478]\n",
      " [180.69861]\n",
      " [196.51456]\n",
      " [141.40628]]\n",
      "1130 Cost:  0.2957312 \n",
      "Prediction:\n",
      " [[151.68372]\n",
      " [184.47543]\n",
      " [180.69832]\n",
      " [196.51424]\n",
      " [141.40724]]\n",
      "1140 Cost:  0.2953433 \n",
      "Prediction:\n",
      " [[151.68274]\n",
      " [184.4761 ]\n",
      " [180.69804]\n",
      " [196.51393]\n",
      " [141.40822]]\n",
      "1150 Cost:  0.29495627 \n",
      "Prediction:\n",
      " [[151.6818 ]\n",
      " [184.47676]\n",
      " [180.69777]\n",
      " [196.51361]\n",
      " [141.40918]]\n",
      "1160 Cost:  0.2945642 \n",
      "Prediction:\n",
      " [[151.68083]\n",
      " [184.47743]\n",
      " [180.69748]\n",
      " [196.5133 ]\n",
      " [141.41016]]\n",
      "1170 Cost:  0.29418224 \n",
      "Prediction:\n",
      " [[151.67989]\n",
      " [184.47809]\n",
      " [180.6972 ]\n",
      " [196.513  ]\n",
      " [141.41112]]\n",
      "1180 Cost:  0.2937981 \n",
      "Prediction:\n",
      " [[151.67894]\n",
      " [184.47874]\n",
      " [180.69693]\n",
      " [196.51268]\n",
      " [141.41208]]\n",
      "1190 Cost:  0.29341486 \n",
      "Prediction:\n",
      " [[151.678  ]\n",
      " [184.47942]\n",
      " [180.69666]\n",
      " [196.51237]\n",
      " [141.41304]]\n",
      "1200 Cost:  0.29303265 \n",
      "Prediction:\n",
      " [[151.67705]\n",
      " [184.48007]\n",
      " [180.69638]\n",
      " [196.51205]\n",
      " [141.414  ]]\n",
      "1210 Cost:  0.29265454 \n",
      "Prediction:\n",
      " [[151.6761 ]\n",
      " [184.48073]\n",
      " [180.6961 ]\n",
      " [196.51175]\n",
      " [141.41496]]\n",
      "1220 Cost:  0.29227582 \n",
      "Prediction:\n",
      " [[151.67517]\n",
      " [184.4814 ]\n",
      " [180.69583]\n",
      " [196.51144]\n",
      " [141.41591]]\n",
      "1230 Cost:  0.2919044 \n",
      "Prediction:\n",
      " [[151.67424]\n",
      " [184.48204]\n",
      " [180.69556]\n",
      " [196.51114]\n",
      " [141.41685]]\n",
      "1240 Cost:  0.29152626 \n",
      "Prediction:\n",
      " [[151.67332]\n",
      " [184.48271]\n",
      " [180.6953 ]\n",
      " [196.51083]\n",
      " [141.41782]]\n",
      "1250 Cost:  0.29115584 \n",
      "Prediction:\n",
      " [[151.67236]\n",
      " [184.48332]\n",
      " [180.69499]\n",
      " [196.5105 ]\n",
      " [141.41875]]\n",
      "1260 Cost:  0.29079786 \n",
      "Prediction:\n",
      " [[151.67145]\n",
      " [184.484  ]\n",
      " [180.69476]\n",
      " [196.51022]\n",
      " [141.4197 ]]\n",
      "1270 Cost:  0.29042286 \n",
      "Prediction:\n",
      " [[151.67052]\n",
      " [184.48462]\n",
      " [180.69447]\n",
      " [196.50989]\n",
      " [141.42064]]\n",
      "1280 Cost:  0.2900596 \n",
      "Prediction:\n",
      " [[151.66959]\n",
      " [184.48528]\n",
      " [180.6942 ]\n",
      " [196.5096 ]\n",
      " [141.42157]]\n",
      "1290 Cost:  0.28970173 \n",
      "Prediction:\n",
      " [[151.66869]\n",
      " [184.48592]\n",
      " [180.69395]\n",
      " [196.5093 ]\n",
      " [141.4225 ]]\n",
      "1300 Cost:  0.2893379 \n",
      "Prediction:\n",
      " [[151.66777]\n",
      " [184.48656]\n",
      " [180.69368]\n",
      " [196.509  ]\n",
      " [141.42345]]\n",
      "1310 Cost:  0.28898272 \n",
      "Prediction:\n",
      " [[151.66685]\n",
      " [184.4872 ]\n",
      " [180.69342]\n",
      " [196.50871]\n",
      " [141.42438]]\n",
      "1320 Cost:  0.2886142 \n",
      "Prediction:\n",
      " [[151.66594]\n",
      " [184.48784]\n",
      " [180.69313]\n",
      " [196.50838]\n",
      " [141.4253 ]]\n",
      "1330 Cost:  0.2882605 \n",
      "Prediction:\n",
      " [[151.66502]\n",
      " [184.48846]\n",
      " [180.69287]\n",
      " [196.50809]\n",
      " [141.42624]]\n",
      "1340 Cost:  0.2879095 \n",
      "Prediction:\n",
      " [[151.66412]\n",
      " [184.48909]\n",
      " [180.69261]\n",
      " [196.50778]\n",
      " [141.42715]]\n",
      "1350 Cost:  0.28756145 \n",
      "Prediction:\n",
      " [[151.66321]\n",
      " [184.48973]\n",
      " [180.69235]\n",
      " [196.50749]\n",
      " [141.42807]]\n",
      "1360 Cost:  0.2872036 \n",
      "Prediction:\n",
      " [[151.66232]\n",
      " [184.49037]\n",
      " [180.6921 ]\n",
      " [196.50719]\n",
      " [141.429  ]]\n",
      "1370 Cost:  0.2868597 \n",
      "Prediction:\n",
      " [[151.6614 ]\n",
      " [184.49098]\n",
      " [180.69182]\n",
      " [196.50688]\n",
      " [141.4299 ]]\n",
      "1380 Cost:  0.286514 \n",
      "Prediction:\n",
      " [[151.66052]\n",
      " [184.49162]\n",
      " [180.69157]\n",
      " [196.5066 ]\n",
      " [141.43083]]\n",
      "1390 Cost:  0.2861667 \n",
      "Prediction:\n",
      " [[151.65962]\n",
      " [184.49223]\n",
      " [180.6913 ]\n",
      " [196.50629]\n",
      " [141.43173]]\n",
      "1400 Cost:  0.28581992 \n",
      "Prediction:\n",
      " [[151.65875]\n",
      " [184.49286]\n",
      " [180.69104]\n",
      " [196.506  ]\n",
      " [141.43265]]\n",
      "1410 Cost:  0.2854824 \n",
      "Prediction:\n",
      " [[151.65785]\n",
      " [184.49347]\n",
      " [180.6908 ]\n",
      " [196.50569]\n",
      " [141.43356]]\n",
      "1420 Cost:  0.28514287 \n",
      "Prediction:\n",
      " [[151.65697]\n",
      " [184.4941 ]\n",
      " [180.69054]\n",
      " [196.5054 ]\n",
      " [141.43446]]\n",
      "1430 Cost:  0.28480425 \n",
      "Prediction:\n",
      " [[151.65608]\n",
      " [184.49472]\n",
      " [180.69028]\n",
      " [196.50511]\n",
      " [141.43536]]\n",
      "1440 Cost:  0.28446534 \n",
      "Prediction:\n",
      " [[151.6552 ]\n",
      " [184.49532]\n",
      " [180.69   ]\n",
      " [196.5048 ]\n",
      " [141.43626]]\n",
      "1450 Cost:  0.28413126 \n",
      "Prediction:\n",
      " [[151.65433]\n",
      " [184.49596]\n",
      " [180.68977]\n",
      " [196.50453]\n",
      " [141.43718]]\n",
      "1460 Cost:  0.28379956 \n",
      "Prediction:\n",
      " [[151.65346]\n",
      " [184.49655]\n",
      " [180.68951]\n",
      " [196.50423]\n",
      " [141.43806]]\n",
      "1470 Cost:  0.28346735 \n",
      "Prediction:\n",
      " [[151.65257]\n",
      " [184.49716]\n",
      " [180.68925]\n",
      " [196.50394]\n",
      " [141.43896]]\n",
      "1480 Cost:  0.28314188 \n",
      "Prediction:\n",
      " [[151.6517 ]\n",
      " [184.49777]\n",
      " [180.68901]\n",
      " [196.50363]\n",
      " [141.43983]]\n",
      "1490 Cost:  0.2828123 \n",
      "Prediction:\n",
      " [[151.65083]\n",
      " [184.49837]\n",
      " [180.68875]\n",
      " [196.50334]\n",
      " [141.44073]]\n",
      "1500 Cost:  0.28248423 \n",
      "Prediction:\n",
      " [[151.64996]\n",
      " [184.49898]\n",
      " [180.68849]\n",
      " [196.50304]\n",
      " [141.4416 ]]\n",
      "1510 Cost:  0.28215837 \n",
      "Prediction:\n",
      " [[151.64911]\n",
      " [184.49959]\n",
      " [180.68825]\n",
      " [196.50276]\n",
      " [141.4425 ]]\n",
      "1520 Cost:  0.2818306 \n",
      "Prediction:\n",
      " [[151.64825]\n",
      " [184.5002 ]\n",
      " [180.688  ]\n",
      " [196.50246]\n",
      " [141.44339]]\n",
      "1530 Cost:  0.28151628 \n",
      "Prediction:\n",
      " [[151.64737]\n",
      " [184.50078]\n",
      " [180.68774]\n",
      " [196.50217]\n",
      " [141.44426]]\n",
      "1540 Cost:  0.28118992 \n",
      "Prediction:\n",
      " [[151.64653]\n",
      " [184.50137]\n",
      " [180.68748]\n",
      " [196.50188]\n",
      " [141.44514]]\n",
      "1550 Cost:  0.2808804 \n",
      "Prediction:\n",
      " [[151.64566]\n",
      " [184.50197]\n",
      " [180.68726]\n",
      " [196.50159]\n",
      " [141.44601]]\n",
      "1560 Cost:  0.2805526 \n",
      "Prediction:\n",
      " [[151.64482]\n",
      " [184.50258]\n",
      " [180.687  ]\n",
      " [196.5013 ]\n",
      " [141.4469 ]]\n",
      "1570 Cost:  0.2802456 \n",
      "Prediction:\n",
      " [[151.64397]\n",
      " [184.50317]\n",
      " [180.68677]\n",
      " [196.50102]\n",
      " [141.44777]]\n",
      "1580 Cost:  0.27993298 \n",
      "Prediction:\n",
      " [[151.64313]\n",
      " [184.50375]\n",
      " [180.68652]\n",
      " [196.50073]\n",
      " [141.44864]]\n",
      "1590 Cost:  0.2796181 \n",
      "Prediction:\n",
      " [[151.64229]\n",
      " [184.50435]\n",
      " [180.68628]\n",
      " [196.50044]\n",
      " [141.44951]]\n",
      "1600 Cost:  0.2793084 \n",
      "Prediction:\n",
      " [[151.64143]\n",
      " [184.50493]\n",
      " [180.68602]\n",
      " [196.50015]\n",
      " [141.45036]]\n",
      "1610 Cost:  0.27899292 \n",
      "Prediction:\n",
      " [[151.64061]\n",
      " [184.50552]\n",
      " [180.68578]\n",
      " [196.49986]\n",
      " [141.45123]]\n",
      "1620 Cost:  0.27868897 \n",
      "Prediction:\n",
      " [[151.63976]\n",
      " [184.5061 ]\n",
      " [180.68553]\n",
      " [196.49957]\n",
      " [141.45209]]\n",
      "1630 Cost:  0.27837807 \n",
      "Prediction:\n",
      " [[151.63893]\n",
      " [184.5067 ]\n",
      " [180.68529]\n",
      " [196.4993 ]\n",
      " [141.45296]]\n",
      "1640 Cost:  0.2780754 \n",
      "Prediction:\n",
      " [[151.6381 ]\n",
      " [184.50728]\n",
      " [180.68506]\n",
      " [196.49901]\n",
      " [141.45381]]\n",
      "1650 Cost:  0.27777758 \n",
      "Prediction:\n",
      " [[151.63727]\n",
      " [184.50784]\n",
      " [180.68481]\n",
      " [196.49873]\n",
      " [141.45467]]\n",
      "1660 Cost:  0.27747214 \n",
      "Prediction:\n",
      " [[151.63646]\n",
      " [184.50845]\n",
      " [180.6846 ]\n",
      " [196.49846]\n",
      " [141.45554]]\n",
      "1670 Cost:  0.27717742 \n",
      "Prediction:\n",
      " [[151.6356 ]\n",
      " [184.509  ]\n",
      " [180.68434]\n",
      " [196.49815]\n",
      " [141.45636]]\n",
      "1680 Cost:  0.2768744 \n",
      "Prediction:\n",
      " [[151.6348 ]\n",
      " [184.50958]\n",
      " [180.6841 ]\n",
      " [196.49788]\n",
      " [141.45721]]\n",
      "1690 Cost:  0.27658185 \n",
      "Prediction:\n",
      " [[151.63397]\n",
      " [184.51016]\n",
      " [180.68387]\n",
      " [196.4976 ]\n",
      " [141.45805]]\n",
      "1700 Cost:  0.27628446 \n",
      "Prediction:\n",
      " [[151.63316]\n",
      " [184.51073]\n",
      " [180.68364]\n",
      " [196.49731]\n",
      " [141.45891]]\n",
      "1710 Cost:  0.27598804 \n",
      "Prediction:\n",
      " [[151.63234]\n",
      " [184.51129]\n",
      " [180.68338]\n",
      " [196.49704]\n",
      " [141.45975]]\n",
      "1720 Cost:  0.27570587 \n",
      "Prediction:\n",
      " [[151.63153]\n",
      " [184.51186]\n",
      " [180.68317]\n",
      " [196.49677]\n",
      " [141.46057]]\n",
      "1730 Cost:  0.2754077 \n",
      "Prediction:\n",
      " [[151.63072]\n",
      " [184.51244]\n",
      " [180.68294]\n",
      " [196.49648]\n",
      " [141.46143]]\n",
      "1740 Cost:  0.2751209 \n",
      "Prediction:\n",
      " [[151.6299 ]\n",
      " [184.513  ]\n",
      " [180.6827 ]\n",
      " [196.4962 ]\n",
      " [141.46225]]\n",
      "1750 Cost:  0.27483124 \n",
      "Prediction:\n",
      " [[151.6291 ]\n",
      " [184.51357]\n",
      " [180.68246]\n",
      " [196.49593]\n",
      " [141.46309]]\n",
      "1760 Cost:  0.27454036 \n",
      "Prediction:\n",
      " [[151.6283 ]\n",
      " [184.51413]\n",
      " [180.68222]\n",
      " [196.49565]\n",
      " [141.46393]]\n",
      "1770 Cost:  0.27425462 \n",
      "Prediction:\n",
      " [[151.62749]\n",
      " [184.5147 ]\n",
      " [180.68199]\n",
      " [196.49536]\n",
      " [141.46475]]\n",
      "1780 Cost:  0.2739754 \n",
      "Prediction:\n",
      " [[151.6267 ]\n",
      " [184.51524]\n",
      " [180.68175]\n",
      " [196.4951 ]\n",
      " [141.46556]]\n",
      "1790 Cost:  0.27369264 \n",
      "Prediction:\n",
      " [[151.6259 ]\n",
      " [184.5158 ]\n",
      " [180.68153]\n",
      " [196.49481]\n",
      " [141.4664 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800 Cost:  0.2734128 \n",
      "Prediction:\n",
      " [[151.6251 ]\n",
      " [184.51636]\n",
      " [180.6813 ]\n",
      " [196.49455]\n",
      " [141.46722]]\n",
      "1810 Cost:  0.27312967 \n",
      "Prediction:\n",
      " [[151.62431]\n",
      " [184.51692]\n",
      " [180.68106]\n",
      " [196.49428]\n",
      " [141.46803]]\n",
      "1820 Cost:  0.2728539 \n",
      "Prediction:\n",
      " [[151.62354]\n",
      " [184.51747]\n",
      " [180.68086]\n",
      " [196.494  ]\n",
      " [141.46887]]\n",
      "1830 Cost:  0.27257645 \n",
      "Prediction:\n",
      " [[151.62273]\n",
      " [184.518  ]\n",
      " [180.6806 ]\n",
      " [196.49371]\n",
      " [141.46967]]\n",
      "1840 Cost:  0.27230114 \n",
      "Prediction:\n",
      " [[151.62195]\n",
      " [184.51855]\n",
      " [180.68039]\n",
      " [196.49344]\n",
      " [141.47049]]\n",
      "1850 Cost:  0.27202487 \n",
      "Prediction:\n",
      " [[151.62115]\n",
      " [184.5191 ]\n",
      " [180.68016]\n",
      " [196.49315]\n",
      " [141.4713 ]]\n",
      "1860 Cost:  0.27174774 \n",
      "Prediction:\n",
      " [[151.62039]\n",
      " [184.51967]\n",
      " [180.67993]\n",
      " [196.49289]\n",
      " [141.4721 ]]\n",
      "1870 Cost:  0.27148595 \n",
      "Prediction:\n",
      " [[151.6196 ]\n",
      " [184.5202 ]\n",
      " [180.67972]\n",
      " [196.49263]\n",
      " [141.47292]]\n",
      "1880 Cost:  0.27121535 \n",
      "Prediction:\n",
      " [[151.61882]\n",
      " [184.52074]\n",
      " [180.67949]\n",
      " [196.49236]\n",
      " [141.47372]]\n",
      "1890 Cost:  0.2709402 \n",
      "Prediction:\n",
      " [[151.61806]\n",
      " [184.5213 ]\n",
      " [180.67926]\n",
      " [196.4921 ]\n",
      " [141.47453]]\n",
      "1900 Cost:  0.27067116 \n",
      "Prediction:\n",
      " [[151.61728]\n",
      " [184.52184]\n",
      " [180.67903]\n",
      " [196.4918 ]\n",
      " [141.47533]]\n",
      "1910 Cost:  0.27040976 \n",
      "Prediction:\n",
      " [[151.6165 ]\n",
      " [184.52238]\n",
      " [180.67882]\n",
      " [196.49156]\n",
      " [141.47614]]\n",
      "1920 Cost:  0.2701426 \n",
      "Prediction:\n",
      " [[151.61574]\n",
      " [184.5229 ]\n",
      " [180.67859]\n",
      " [196.49127]\n",
      " [141.47693]]\n",
      "1930 Cost:  0.2698774 \n",
      "Prediction:\n",
      " [[151.61497]\n",
      " [184.52345]\n",
      " [180.67838]\n",
      " [196.491  ]\n",
      " [141.47772]]\n",
      "1940 Cost:  0.2696175 \n",
      "Prediction:\n",
      " [[151.61421]\n",
      " [184.52397]\n",
      " [180.67815]\n",
      " [196.49074]\n",
      " [141.47852]]\n",
      "1950 Cost:  0.26935652 \n",
      "Prediction:\n",
      " [[151.61345]\n",
      " [184.5245 ]\n",
      " [180.67793]\n",
      " [196.49046]\n",
      " [141.47931]]\n",
      "1960 Cost:  0.26909387 \n",
      "Prediction:\n",
      " [[151.6127 ]\n",
      " [184.52505]\n",
      " [180.67772]\n",
      " [196.4902 ]\n",
      " [141.4801 ]]\n",
      "1970 Cost:  0.26883292 \n",
      "Prediction:\n",
      " [[151.61194]\n",
      " [184.52557]\n",
      " [180.67749]\n",
      " [196.48993]\n",
      " [141.4809 ]]\n",
      "1980 Cost:  0.26858062 \n",
      "Prediction:\n",
      " [[151.61119]\n",
      " [184.52611]\n",
      " [180.67728]\n",
      " [196.48969]\n",
      " [141.48167]]\n",
      "1990 Cost:  0.26832825 \n",
      "Prediction:\n",
      " [[151.61043]\n",
      " [184.52663]\n",
      " [180.67706]\n",
      " [196.48941]\n",
      " [141.48245]]\n",
      "2000 Cost:  0.26806805 \n",
      "Prediction:\n",
      " [[151.60968]\n",
      " [184.52716]\n",
      " [180.67685]\n",
      " [196.48914]\n",
      " [141.48325]]\n"
     ]
    }
   ],
   "source": [
    "# Multi-variable 다변수회귀 - 매트릭스 사용\n",
    "\n",
    "x_data = [[73., 80., 75.],\n",
    "          [93., 88., 93.],\n",
    "          [89., 91., 90.],\n",
    "          [96., 98., 100.],\n",
    "          [73., 66., 70.]]\n",
    "y_data = [[152.],\n",
    "          [185.],\n",
    "          [180.],\n",
    "          [196.],\n",
    "          [142.]]\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3]) # X는 n x 3\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1]) # Y는 n x 1\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name='weight') # W는 3 x 1\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias') # b는 1x1\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b # 행렬곱을 tf.matmul() 함수를 이용해서 계산\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "        [cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "    if step % 10 == 0:\n",
    "        print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensorflow로 파일에서 데이터 읽어오기\n",
    "\n",
    "import numpy as np\n",
    "data = np.loadtext('data.csv', delimiter = ',' , dtype = np.float32) # 일단 numpy를 이용해 데이터 일어들이기\n",
    "#이후 data를 적당히 slice 후 사용\n",
    "\n",
    "#혹은 여러개의 파일을 queue 형식으로 읽어들이려면\n",
    "ilename_queue = tf.train.string_input_producer(\n",
    "    ['data1.csv','data2.csv', ... ], shuffle=False, name='filename_queue')\n",
    "\n",
    "reader = tf.TextLineReader()\n",
    "key, value = reader.read(filename_queue)\n",
    "\n",
    "record_defaults = [[0.], [0.], [0.], [0.]]\n",
    "xy = tf.decode_csv(value, record_defaults=record_defaults) # record_defaluts는 어떤 형식으로 읽어올건지, 지금은 float형식으로 읽어들인다는 뜻\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
