{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 3, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21a1f7364e0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "CNN\n",
    "\n",
    "1. N x N x h 의 이미지를 k x k x h 필터로 strdie = j 의 값으로 필터링 한다 -> 1개의 (N - k)/j +1 x (N- k)/j +1 의 레이어가 나온다 (이 때 가중치는 k x 1이 될 것)\n",
    "2. 1의 과정을 서로다른 필터 u개를 이용해 u번 반복한다 -> (N - k)/j +1  x (N- k)/j + 1의 conv layer가 u개 생성\n",
    "3. u개의 conv layer를 한층씩 polling해서 크기를 줄인 후 u개의 pooling layer를 생성한다 -> 풀링에서의 필터크기 t, stride가 y일 때 u개의 T x T 레이어가 생성(T = [{(N - k)/j +1} - t]/y + 1)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "image = np.array([[[[1],[2],[3]],\n",
    "                   [[4],[5],[6]], \n",
    "                   [[7],[8],[9]]]], dtype=np.float32)\n",
    "print(image.shape)\n",
    "plt.imshow(image.reshape(3,3), cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image.shape (1, 3, 3, 1)\n",
      "weight.shape (2, 2, 1, 1)\n",
      "conv2d_img.shape (1, 2, 2, 1)\n",
      "[[12. 16.]\n",
      " [24. 28.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 이미지 : 1, 3, 3, 1(이미지개수, 가로, 세로, 흑백여부)\n",
    "# 필터 : 2, 2, 1, 1(가로,세로, 흑백여부, 필터개수)\n",
    "# 스트라이드 : 1 x 1\n",
    "\n",
    "print(\"image.shape\", image.shape)\n",
    "weight = tf.constant([[[[1.]],[[1.]]],\n",
    "                      [[[1.]],[[1.]]]])\n",
    "print(\"weight.shape\", weight.shape)\n",
    "conv2d = tf.nn.conv2d(image, weight, strides=[1, 1, 1, 1], padding='VALID') # stride에서는 2번째 3번쨰 값이 1x1이 들어가는 부분\n",
    "conv2d_img = conv2d.eval()\n",
    "print(\"conv2d_img.shape\", conv2d_img.shape)\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(2,2))\n",
    "    plt.subplot(1,2,i+1), plt.imshow(one_img.reshape(2,2), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight.shape (2, 2, 1, 1)\n",
      "conv2d_img.shape (1, 3, 3, 1)\n",
      "[[12. 16.  9.]\n",
      " [24. 28. 15.]\n",
      " [15. 17.  9.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "weight = tf.constant([[[[1.]],[[1.]]],\n",
    "                      [[[1.]],[[1.]]]])\n",
    "print(\"weight.shape\", weight.shape)\n",
    "conv2d = tf.nn.conv2d(image, weight, strides=[1, 1, 1, 1], padding='SAME') # 패딩은 무조건 출력이 이미지의 원래 크기와 같게 함\n",
    "conv2d_img = conv2d.eval()\n",
    "print(\"conv2d_img.shape\", conv2d_img.shape)\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(3,3))\n",
    "    plt.subplot(1,2,i+1), plt.imshow(one_img.reshape(3,3), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image.shape (1, 3, 3, 1)\n",
      "weight.shape (2, 2, 1, 3)\n",
      "conv2d_img.shape (1, 3, 3, 3)\n",
      "[[12. 16.  9.]\n",
      " [24. 28. 15.]\n",
      " [15. 17.  9.]]\n",
      "[[120. 160.  90.]\n",
      " [240. 280. 150.]\n",
      " [150. 170.  90.]]\n",
      "[[-12. -16.  -9.]\n",
      " [-24. -28. -15.]\n",
      " [-15. -17.  -9.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2 x 2 필터를 3개 사용하는 경우\n",
    "print(\"image.shape\", image.shape)\n",
    "\n",
    "weight = tf.constant([[[[1.,10.,-1.]],[[1.,10.,-1.]]],\n",
    "                      [[[1.,10.,-1.]],[[1.,10.,-1.]]]])\n",
    "print(\"weight.shape\", weight.shape)\n",
    "conv2d = tf.nn.conv2d(image, weight, strides=[1, 1, 1, 1], padding='SAME')\n",
    "conv2d_img = conv2d.eval()\n",
    "print(\"conv2d_img.shape\", conv2d_img.shape)\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(3,3))\n",
    "    plt.subplot(1,3,i+1), plt.imshow(one_img.reshape(3,3), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 1, 1)\n",
      "[[[[4.]]]]\n"
     ]
    }
   ],
   "source": [
    "#풀링 - 2x2 이미지를 2x2 사이즈의 풀링으로 시행 -> 결과는 1 x 1로 나옴\n",
    "image = np.array([[[[4],[3]],\n",
    "                    [[2],[1]]]], dtype=np.float32)\n",
    "pool = tf.nn.max_pool(image, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 1, 1, 1], padding='VALID') #max_pooling에서 ksize가 풀링의 사이즈가 됨\n",
    "print(pool.shape)\n",
    "print(pool.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 2, 1)\n",
      "[[[[4.]\n",
      "   [3.]]\n",
      "\n",
      "  [[2.]\n",
      "   [1.]]]]\n"
     ]
    }
   ],
   "source": [
    "#제로패딩 풀링 ->  입력과 출력의 shape가 같음\n",
    "image = np.array([[[[4],[3]],\n",
    "                    [[2],[1]]]], dtype=np.float32)\n",
    "pool = tf.nn.max_pool(image, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 1, 1, 1], padding='SAME')\n",
    "print(pool.shape)\n",
    "print(pool.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-61dc0b3d8f41>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\1\\anaconda3\\envs\\virtualtensor3.6\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\1\\anaconda3\\envs\\virtualtensor3.6\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\1\\anaconda3\\envs\\virtualtensor3.6\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\1\\anaconda3\\envs\\virtualtensor3.6\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\1\\anaconda3\\envs\\virtualtensor3.6\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21a25301860>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MNIST 이미지 데이터 사용\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "#예시\n",
    "img = mnist.train.images[0].reshape(28,28)\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1\\anaconda3\\envs\\virtualtensor3.6\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1714: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Conv2D_3:0\", shape=(1, 14, 14, 5), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convolutional layer \n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "img = img.reshape(-1,28,28,1) # n개의 28 x 28 픽셀의 흑백 이미지 \n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 5], stddev=0.01)) # 필터는 3 x 3, 흑백, 레이어는 총 5개\n",
    "conv2d = tf.nn.conv2d(img, W1, strides=[1, 2, 2, 1], padding='SAME') # 패딩 same + stride가 2면 입력/2 의 값으로 출력이 됨\n",
    "print(conv2d)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "conv2d_img = conv2d.eval()\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    plt.subplot(1,5,i+1), plt.imshow(one_img.reshape(14,14), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MaxPool_2:0\", shape=(1, 7, 7, 5), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#풀링(맥스풀링)\n",
    "pool = tf.nn.max_pool(conv2d, ksize=[1, 2, 2, 1], strides=[\n",
    "                        1, 2, 2, 1], padding='SAME') # 이역시 패딩 SAME + strde는 2이므로 결과는 14의 절반인 7 x 7로 나옴\n",
    "print(pool)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "pool_img = pool.eval()\n",
    "pool_img = np.swapaxes(pool_img, 0, 3)\n",
    "for i, one_img in enumerate(pool_img):\n",
    "    plt.subplot(1,5,i+1), plt.imshow(one_img.reshape(7, 7), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST CNN 예측모델\n",
    "\n",
    "import tensorflow as tf\n",
    "import random\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # 시드가 같으면 생성되는 난수가 동일 -> 난수를 이용해도 다른 컴퓨터에서 동일한 결과를 얻을 수 있음\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset\n",
    "\n",
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])   # img 28x28x1 (black/white)\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# L1 ImgIn shape=(?, 28, 28, 1)\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01)) # 3x3 흑백 필터 32개 이용(가중치 = 필터)\n",
    "#    Conv     -> (?, 28, 28, 32)\n",
    "#    Pool     -> (?, 14, 14, 32)\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 2, 2, 1], padding='SAME')\n",
    "'''\n",
    "Tensor(\"Conv2D:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "Tensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "Tensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32) -> 첫번째 CONV + POOL Layer를 통과시킨 후 shpe -> 기억!\n",
    "'''\n",
    "\n",
    "# L2 ImgIn shape=(?, 14, 14, 32)\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01)) #레이어가 32개이기 때문에 (.,., 32, .)로 맞춰줘야 함(컬로도 사실 레이어 3개가 겹쳐진 것이란걸 기억하면 이해하기 쉬움), 여기서 다시 3x3필터를 이용 64개의 레이어로 만듬\n",
    "#    Conv      ->(?, 14, 14, 64)\n",
    "#    Pool      ->(?, 7, 7, 64)\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 2, 2, 1], padding='SAME')\n",
    "L2_flat = tf.reshape(L2, [-1, 7 * 7 * 64]) # FC(fully connected) 에 넣기 전 이미지를 flattening하는 작업\n",
    "'''\n",
    "Tensor(\"Conv2D_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "Tensor(\"Relu_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "Tensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
    "Tensor(\"Reshape_1:0\", shape=(?, 3136), dtype=float32)\n",
    "'''\n",
    "\n",
    "# Final FC 7x7x64 inputs -> 10 outputs\n",
    "W3 = tf.get_variable(\"W3\", shape=[7 * 7 * 64, 10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer()) # 7x7x64의 값을 10개의 값(0~9까지)으로 분류\n",
    "b = tf.Variable(tf.random_normal([10]))\n",
    "logits = tf.matmul(L2_flat, W3) + b\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1)) #예측과 레이블이 동일한지(tf.equl) 불린 값으로 구성된 리스트로 반납(ex) [1., 0., 1., 1., 0.] ex\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) #위에서 받은 리스트에서 부동소수점을 제거하고(cast) 평균을 구함(reduce_mean ; reduce_mean은 그냥 단순히 평균 구하는 함수! reduce에 의미 부여 X)\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(logits, 1), feed_dict={X: mnist.test.images[r:r + 1]}))\n",
    "\n",
    "# plt.imshow(mnist.test.images[r:r + 1].\n",
    "#           reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 드랍아웃을 적용한 더 깊어진 MNIST 예측모델\n",
    "import tensorflow as tf\n",
    "import random\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset\n",
    "\n",
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# dropout (keep_prob) rate  0.7~0.5 on training, but should be 1 for testing\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])   # img 28x28x1 (black/white)\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# L1 ImgIn shape=(?, 28, 28, 1)\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "#    Conv     -> (?, 28, 28, 32)\n",
    "#    Pool     -> (?, 14, 14, 32)\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 2, 2, 1], padding='SAME')\n",
    "L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "'''\n",
    "Tensor(\"Conv2D:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "Tensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "Tensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
    "Tensor(\"dropout/mul:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
    "'''\n",
    "\n",
    "# L2 ImgIn shape=(?, 14, 14, 32)\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "#    Conv      ->(?, 14, 14, 64)\n",
    "#    Pool      ->(?, 7, 7, 64)\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 2, 2, 1], padding='SAME')\n",
    "L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "'''\n",
    "Tensor(\"Conv2D_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "Tensor(\"Relu_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "Tensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
    "Tensor(\"dropout_1/mul:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
    "'''\n",
    "\n",
    "# L3 ImgIn shape=(?, 7, 7, 64)\n",
    "W3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))\n",
    "#    Conv      ->(?, 7, 7, 128)\n",
    "#    Pool      ->(?, 4, 4, 128)\n",
    "#    Reshape   ->(?, 4 * 4 * 128) # Flatten them for FC\n",
    "L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L3 = tf.nn.relu(L3)\n",
    "L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1], strides=[\n",
    "                    1, 2, 2, 1], padding='SAME')\n",
    "L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "L3_flat = tf.reshape(L3, [-1, 128 * 4 * 4])\n",
    "'''\n",
    "Tensor(\"Conv2D_2:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
    "Tensor(\"Relu_2:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
    "Tensor(\"MaxPool_2:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
    "Tensor(\"dropout_2/mul:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
    "Tensor(\"Reshape_1:0\", shape=(?, 2048), dtype=float32)\n",
    "'''\n",
    "\n",
    "# L4 FC 4x4x128 inputs -> 625 outputs\n",
    "W4 = tf.get_variable(\"W4\", shape=[128 * 4 * 4, 625],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([625]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3_flat, W4) + b4)\n",
    "L4 = tf.nn.dropout(L4, keep_prob=keep_prob)\n",
    "'''\n",
    "Tensor(\"Relu_3:0\", shape=(?, 625), dtype=float32)\n",
    "Tensor(\"dropout_3/mul:0\", shape=(?, 625), dtype=float32)\n",
    "'''\n",
    "\n",
    "# L5 Final FC 625 inputs -> 10 outputs\n",
    "W5 = tf.get_variable(\"W5\", shape=[625, 10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "logits = tf.matmul(L4, W5) + b5\n",
    "'''\n",
    "Tensor(\"add_1:0\", shape=(?, 10), dtype=float32)\n",
    "'''\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "\n",
    "# if you have a OOM error, please refer to lab-11-X-mnist_deep_cnn_low_memory.py\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(logits, 1), feed_dict={X: mnist.test.images[r:r + 1], keep_prob: 1}))\n",
    "\n",
    "# plt.imshow(mnist.test.images[r:r + 1].\n",
    "#           reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "#tf.argmax사용법\n",
    "\n",
    "#1차원 배열\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(tf.argmax(tf.constant([1, 2, 3]), 0))) #[1, 2, 3] 에서 가장 큰 값이 있는 인덱스를 반환 , tf.argmax()에서 두번째 인수는 차원 - 1 까지의 값만 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0]\n"
     ]
    }
   ],
   "source": [
    "#2차원 배열 - 1\n",
    "with tf.Session() as sess:\n",
    "    a = tf.constant([[1,5,10],[2,8,9]])\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(tf.argmax(a, 0))) #2차원 배열에서 세로 방향으로 가장 큰 값이 있는 인덱스 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2]\n"
     ]
    }
   ],
   "source": [
    "#2차원 배열 - 2\n",
    "with tf.Session() as sess:\n",
    "    a = tf.constant([[1,5,10],[2,8,9]])\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(tf.argmax(a, 1))) #2차원 배열에서 가로 방향으로 가장 큰 값이 있는 인덱스 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1]\n",
      " [1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#3차원 배열 - 1\n",
    "with tf.Session() as sess:\n",
    "    a = tf.constant([[[1,5,10],[2,8,9]],[[6,9,11],[20,6,7]]]) #3차원은 2차원이 2개 이상 들어있음\n",
    "    # 3차원 배열은 \n",
    "    # 2층 : 1 5 10\n",
    "    #       2 8 9\n",
    "    # 1층:  6 9 11\n",
    "    #       20 6 7 이 있는 구조 , 즉 1층의 1 밑에 6, 1층의 5밑에 9, 1층의 10 밑에 11, ... 1층의 9 밑에 7 이렇게 있는 것\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(tf.argmax(a, 0))) #3차원 배열에서 수직 방향으로 가장 큰 값이 있는 인덱스 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0]\n",
      " [1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#3차원 배열 - 2\n",
    "with tf.Session() as sess:\n",
    "    a = tf.constant([[[1,5,10],[2,8,9]],[[6,9,11],[20,6,7]]]) #3차원은 2차원이 2개 이상 들어있음\n",
    "    # 3차원 배열은 \n",
    "    # 2층 : 1 5 10\n",
    "    #       2 8 9\n",
    "    # 1층:  6 9 11\n",
    "    #       20 6 7 이 있는 구조 , 즉 1층의 1 밑에 6, 1층의 5밑에 9, 1층의 10 밑에 11, ... 1층의 9 밑에 7 이렇게 있는 것\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(tf.argmax(a, 1))) #3차원 배열에서 층끼리 비교해서(1행은 2층의 1과 2, 2층의 5와 8, ...) 가장 큰 값이 있는 인덱스 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 2]\n",
      " [2 0]]\n"
     ]
    }
   ],
   "source": [
    "#3차원 배열 - 3\n",
    "with tf.Session() as sess:\n",
    "    a = tf.constant([[[1,5,10],[2,8,9]],[[6,9,11],[20,6,7]]]) #3차원은 2차원이 2개 이상 들어있음\n",
    "    # 3차원 배열은 \n",
    "    # 2층 : 1 5 10\n",
    "    #       2 8 9\n",
    "    # 1층:  6 9 11\n",
    "    #       20 6 7 이 있는 구조 , 즉 1층의 1 밑에 6, 1층의 5밑에 9, 1층의 10 밑에 11, ... 1층의 9 밑에 7 이렇게 있는 것\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(tf.argmax(a, 2))) #3차원 배열에서 수평 방향으로 비교해서 가장 큰 값이 있는 인덱스 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 클래스화 \n",
    "import tensorflow as tf\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset\n",
    "\n",
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "class Model:\n",
    "\n",
    "    def __init__(self, sess, name):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "        self._build_net()\n",
    "\n",
    "    def _build_net(self):\n",
    "        with tf.variable_scope(self.name):\n",
    "            # dropout (keep_prob) rate  0.7~0.5 on training, but should be 1\n",
    "            # for testing\n",
    "            self.keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "            # input place holders\n",
    "            self.X = tf.placeholder(tf.float32, [None, 784])\n",
    "            # img 28x28x1 (black/white)\n",
    "            X_img = tf.reshape(self.X, [-1, 28, 28, 1])\n",
    "            self.Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "            # L1 ImgIn shape=(?, 28, 28, 1)\n",
    "            W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "            #    Conv     -> (?, 28, 28, 32)\n",
    "            #    Pool     -> (?, 14, 14, 32)\n",
    "            L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            L1 = tf.nn.relu(L1)\n",
    "            L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1],\n",
    "                                strides=[1, 2, 2, 1], padding='SAME')\n",
    "            L1 = tf.nn.dropout(L1, keep_prob=self.keep_prob)\n",
    "            '''\n",
    "            Tensor(\"Conv2D:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "            Tensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "            Tensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
    "            Tensor(\"dropout/mul:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
    "            '''\n",
    "\n",
    "            # L2 ImgIn shape=(?, 14, 14, 32)\n",
    "            W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "            #    Conv      ->(?, 14, 14, 64)\n",
    "            #    Pool      ->(?, 7, 7, 64)\n",
    "            L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            L2 = tf.nn.relu(L2)\n",
    "            L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1],\n",
    "                                strides=[1, 2, 2, 1], padding='SAME')\n",
    "            L2 = tf.nn.dropout(L2, keep_prob=self.keep_prob)\n",
    "            '''\n",
    "            Tensor(\"Conv2D_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "            Tensor(\"Relu_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "            Tensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
    "            Tensor(\"dropout_1/mul:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
    "            '''\n",
    "\n",
    "            # L3 ImgIn shape=(?, 7, 7, 64)\n",
    "            W3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))\n",
    "            #    Conv      ->(?, 7, 7, 128)\n",
    "            #    Pool      ->(?, 4, 4, 128)\n",
    "            #    Reshape   ->(?, 4 * 4 * 128) # Flatten them for FC\n",
    "            L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            L3 = tf.nn.relu(L3)\n",
    "            L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1], strides=[\n",
    "                                1, 2, 2, 1], padding='SAME')\n",
    "            L3 = tf.nn.dropout(L3, keep_prob=self.keep_prob)\n",
    "\n",
    "            L3_flat = tf.reshape(L3, [-1, 128 * 4 * 4])\n",
    "            '''\n",
    "            Tensor(\"Conv2D_2:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
    "            Tensor(\"Relu_2:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
    "            Tensor(\"MaxPool_2:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
    "            Tensor(\"dropout_2/mul:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
    "            Tensor(\"Reshape_1:0\", shape=(?, 2048), dtype=float32)\n",
    "            '''\n",
    "\n",
    "            # L4 FC 4x4x128 inputs -> 625 outputs\n",
    "            W4 = tf.get_variable(\"W4\", shape=[128 * 4 * 4, 625],\n",
    "                                 initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b4 = tf.Variable(tf.random_normal([625]))\n",
    "            L4 = tf.nn.relu(tf.matmul(L3_flat, W4) + b4)\n",
    "            L4 = tf.nn.dropout(L4, keep_prob=self.keep_prob)\n",
    "            '''\n",
    "            Tensor(\"Relu_3:0\", shape=(?, 625), dtype=float32)\n",
    "            Tensor(\"dropout_3/mul:0\", shape=(?, 625), dtype=float32)\n",
    "            '''\n",
    "\n",
    "            # L5 Final FC 625 inputs -> 10 outputs\n",
    "            W5 = tf.get_variable(\"W5\", shape=[625, 10],\n",
    "                                 initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b5 = tf.Variable(tf.random_normal([10]))\n",
    "            self.logits = tf.matmul(L4, W5) + b5\n",
    "            '''\n",
    "            Tensor(\"add_1:0\", shape=(?, 10), dtype=float32)\n",
    "            '''\n",
    "\n",
    "        # define cost/loss & optimizer\n",
    "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits=self.logits, labels=self.Y))\n",
    "        self.optimizer = tf.train.AdamOptimizer(\n",
    "            learning_rate=learning_rate).minimize(self.cost)\n",
    "\n",
    "        correct_prediction = tf.equal(\n",
    "            tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    def predict(self, x_test, keep_prop=1.0):\n",
    "        return self.sess.run(self.logits, feed_dict={self.X: x_test, self.keep_prob: keep_prop})\n",
    "\n",
    "    def get_accuracy(self, x_test, y_test, keep_prop=1.0):\n",
    "        return self.sess.run(self.accuracy, feed_dict={self.X: x_test, self.Y: y_test, self.keep_prob: keep_prop})\n",
    "\n",
    "    def train(self, x_data, y_data, keep_prop=0.7):\n",
    "        return self.sess.run([self.cost, self.optimizer], feed_dict={\n",
    "            self.X: x_data, self.Y: y_data, self.keep_prob: keep_prop})\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "m1 = Model(sess, \"m1\")\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print('Learning Started!')\n",
    "\n",
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        c, _ = m1.train(batch_xs, batch_ys)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "print('Accuracy:', m1.get_accuracy(mnist.test.images, mnist.test.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf. layer를 활용해서 더 간편하게 conv layer 짜는 법\n",
    "# Convolutional Layer #1\n",
    "#             conv1 = tf.layers.conv2d(inputs=X_img, filters=32, kernel_size=[3, 3],\n",
    "#                                      padding=\"SAME\", activation=tf.nn.relu) #tf.layer 를 이용한 conv2d\n",
    "#             # Pooling Layer #1\n",
    "#             pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2],\n",
    "#                                             padding=\"SAME\", strides=2) #tf.layer를 이용한 max_pooling\n",
    "#             dropout1 = tf.layers.dropout(inputs=pool1, \n",
    "#                                          rate=0.3, training=self.training) #tf.layer를 이용한 dropout\n",
    "# Logits (no activation) Layer: L5 Final FC 625 inputs -> 10 outputs\n",
    "#             self.logits = tf.layers.dense(inputs=dropout4, units=10) #tf.layer를 이용한 FC 만들기\n",
    "\n",
    "# 위 코드는 사용법을 알기 위해 전체 코드 중 일부만 발췌해서 뽑아온 것\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앙상블 : 클래스를 이용해 여러개의 모델을 만들고, 여러개의 모델의 prediction을 종합해서 정확성을 높이기\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset\n",
    "\n",
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 20\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "class Model:\n",
    "\n",
    "    def __init__(self, sess, name):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "        self._build_net()\n",
    "\n",
    "    def _build_net(self):\n",
    "        with tf.variable_scope(self.name):\n",
    "            # dropout (keep_prob) rate  0.7~0.5 on training, but should be 1\n",
    "            # for testing\n",
    "            self.training = tf.placeholder(tf.bool)\n",
    "\n",
    "            # input place holders\n",
    "            self.X = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "            # img 28x28x1 (black/white), Input Layer\n",
    "            X_img = tf.reshape(self.X, [-1, 28, 28, 1])\n",
    "            self.Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "            # Convolutional Layer #1\n",
    "            conv1 = tf.layers.conv2d(inputs=X_img, filters=32, kernel_size=[3, 3],\n",
    "                                     padding=\"SAME\", activation=tf.nn.relu)\n",
    "            # Pooling Layer #1\n",
    "            pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2],\n",
    "                                            padding=\"SAME\", strides=2)\n",
    "            dropout1 = tf.layers.dropout(inputs=pool1,\n",
    "                                         rate=0.3, training=self.training)\n",
    "\n",
    "            # Convolutional Layer #2 and Pooling Layer #2\n",
    "            conv2 = tf.layers.conv2d(inputs=dropout1, filters=64, kernel_size=[3, 3],\n",
    "                                     padding=\"SAME\", activation=tf.nn.relu)\n",
    "            pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2],\n",
    "                                            padding=\"SAME\", strides=2)\n",
    "            dropout2 = tf.layers.dropout(inputs=pool2,\n",
    "                                         rate=0.3, training=self.training)\n",
    "\n",
    "            # Convolutional Layer #3 and Pooling Layer #3\n",
    "            conv3 = tf.layers.conv2d(inputs=dropout2, filters=128, kernel_size=[3, 3],\n",
    "                                     padding=\"SAME\", activation=tf.nn.relu)\n",
    "            pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2],\n",
    "                                            padding=\"SAME\", strides=2)\n",
    "            dropout3 = tf.layers.dropout(inputs=pool3,\n",
    "                                         rate=0.3, training=self.training)\n",
    "\n",
    "            # Dense Layer with Relu\n",
    "            flat = tf.reshape(dropout3, [-1, 128 * 4 * 4])\n",
    "            dense4 = tf.layers.dense(inputs=flat,\n",
    "                                     units=625, activation=tf.nn.relu)\n",
    "            dropout4 = tf.layers.dropout(inputs=dense4,\n",
    "                                         rate=0.5, training=self.training)\n",
    "\n",
    "            # Logits (no activation) Layer: L5 Final FC 625 inputs -> 10 outputs\n",
    "            self.logits = tf.layers.dense(inputs=dropout4, units=10)\n",
    "\n",
    "        # define cost/loss & optimizer\n",
    "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits=self.logits, labels=self.Y))\n",
    "        self.optimizer = tf.train.AdamOptimizer(\n",
    "            learning_rate=learning_rate).minimize(self.cost)\n",
    "\n",
    "        correct_prediction = tf.equal(\n",
    "            tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    def predict(self, x_test, training=False):\n",
    "        return self.sess.run(self.logits,\n",
    "                             feed_dict={self.X: x_test, self.training: training})\n",
    "\n",
    "    def get_accuracy(self, x_test, y_test, training=False):\n",
    "        return self.sess.run(self.accuracy,\n",
    "                             feed_dict={self.X: x_test,\n",
    "                                        self.Y: y_test, self.training: training})\n",
    "\n",
    "    def train(self, x_data, y_data, training=True):\n",
    "        return self.sess.run([self.cost, self.optimizer], feed_dict={\n",
    "            self.X: x_data, self.Y: y_data, self.training: training})\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "\n",
    "models = [] #모델을 담을 리스트\n",
    "num_models = 2 #만들 모델의 개수\n",
    "for m in range(num_models):\n",
    "    models.append(Model(sess, \"model\" + str(m)))\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print('Learning Started!')\n",
    "\n",
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost_list = np.zeros(len(models))\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "\n",
    "        # train each model\n",
    "        for m_idx, m in enumerate(models): # 각각의 모델 학습시키기\n",
    "            c, _ = m.train(batch_xs, batch_ys)\n",
    "            avg_cost_list[m_idx] += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', avg_cost_list)\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "test_size = len(mnist.test.labels)\n",
    "predictions = np.zeros([test_size, 10])\n",
    "for m_idx, m in enumerate(models):\n",
    "    print(m_idx, 'Accuracy:', m.get_accuracy(\n",
    "        mnist.test.images, mnist.test.labels))\n",
    "    p = m.predict(mnist.test.images)\n",
    "    predictions += p # 각 모델이 산출한 prediction을 모두 더하기 \n",
    "\n",
    "ensemble_correct_prediction = tf.equal(\n",
    "    tf.argmax(predictions, 1), tf.argmax(mnist.test.labels, 1))\n",
    "ensemble_accuracy = tf.reduce_mean(\n",
    "    tf.cast(ensemble_correct_prediction, tf.float32))\n",
    "print('Ensemble accuracy:', sess.run(ensemble_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
